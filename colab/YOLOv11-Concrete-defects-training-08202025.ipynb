{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "machine_shape": "hm", "gpuType": "A100"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}, "accelerator": "GPU"}, "cells": [{"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "_bI753oUSJ7k", "outputId": "95cdd76f-e3c0-4385-ac91-e636800950b0"}, "outputs": [], "source": ["!nvidia-smi\n"]}, {"cell_type": "code", "source": ["%pip install --upgrade pip\n", "%pip install ultralytics\n", "# If you ever hit cv2/libGL errors, also run:\n", "# %pip install opencv-python-headless\n", "# or (rarely needed):\n", "# !apt-get update && apt-get install -y libgl1\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rmORZTxfTTVR", "outputId": "21781f53-58ee-40ae-ad85-249bdb6297c7"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO('yolo11m-seg.pt')\n", "print(model)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4ZmIaYhTTZw5", "outputId": "2f86ea85-2838-47b1-a2d7-c7987fc4de47"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import torch, platform\n", "print(\"Torch CUDA:\", torch.cuda.is_available(), torch.version.cuda, platform.platform())\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ip5C0cAwVw12", "outputId": "d694e942-3c84-476e-a2e3-ab9548fb9d6e"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "8FKbZrSvWVaH", "outputId": "320fe30b-ed97-4773-bb33-c5c17c1417d5"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import os, shutil, random, math\n", "from pathlib import Path\n", "\n", "# ==== CONFIG ====\n", "BASE = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025\")\n", "DATASET = BASE / \"dataset\"         # where your mixed images+txt live\n", "TRAIN   = BASE / \"train\"           # will be created/overwritten\n", "VAL     = BASE / \"val\"             # will be created/overwritten\n", "VAL_RATIO = 0.17                   # 17% for validation\n", "RANDOM_SEED = 42                   # reproducible split\n", "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\"}  # case-insensitive\n", "OVERWRITE = True                   # delete existing train/val before writing\n", "\n", "# ==== PREP ====\n", "if not DATASET.exists():\n", "    raise FileNotFoundError(f\"Dataset folder not found: {DATASET}\")\n", "\n", "def clean_dir(d: Path):\n", "    if d.exists():\n", "        if OVERWRITE:\n", "            shutil.rmtree(d)\n", "        else:\n", "            raise RuntimeError(f\"{d} exists. Set OVERWRITE=True or rename it first.\")\n", "    d.mkdir(parents=True, exist_ok=True)\n", "\n", "clean_dir(TRAIN)\n", "clean_dir(VAL)\n", "\n", "# ==== COLLECT ELIGIBLE SAMPLES (image + matching .txt) ====\n", "samples = []\n", "for p in DATASET.rglob(\"*\"):\n", "    if p.is_file() and p.suffix.lower() in IMG_EXTS:\n", "        txt = p.with_suffix(\".txt\")\n", "        if txt.exists():\n", "            samples.append((p, txt))\n", "\n", "if not samples:\n", "    raise RuntimeError(f\"No (image, txt) pairs found under {DATASET}\")\n", "\n", "# ==== SHUFFLE & SPLIT ====\n", "random.seed(RANDOM_SEED)\n", "random.shuffle(samples)\n", "n_total = len(samples)\n", "n_val = math.floor(n_total * VAL_RATIO)\n", "val_samples = samples[:n_val]\n", "train_samples = samples[n_val:]\n", "\n", "# ==== COPY ====\n", "def copy_pair(img: Path, txt: Path, dst_dir: Path):\n", "    # Flattens into train/ and val/ (same as your VM script)\n", "    shutil.copy2(img, dst_dir / img.name)\n", "    shutil.copy2(txt, dst_dir / txt.name)\n", "\n", "for img, txt in val_samples:\n", "    copy_pair(img, txt, VAL)\n", "for img, txt in train_samples:\n", "    copy_pair(img, txt, TRAIN)\n", "\n", "# ==== REPORT ====\n", "def count_images(d: Path):\n", "    return sum(1 for f in d.glob(\"*\") if f.suffix.lower() in IMG_EXTS)\n", "def count_txts(d: Path):\n", "    return sum(1 for f in d.glob(\"*.txt\"))\n", "\n", "print(f\"Total pairs found: {n_total}\")\n", "print(f\"Train pairs: {len(train_samples)} | images={count_images(TRAIN)} | labels={count_txts(TRAIN)}\")\n", "print(f\"Val   pairs: {len(val_samples)}   | images={count_images(VAL)}   | labels={count_txts(VAL)}\")\n", "\n", "# ==== WRITE A YOLO DATA YAML ====\n", "# Update class names to your exact mapping if needed.\n", "yaml_text = f\"\"\"# Auto-generated for Colab\n", "path: {BASE}          # project root\n", "train: {TRAIN}        # images in this folder\n", "val: {VAL}            # images in this folder\n", "\n", "names:\n", "  0: Crack\n", "  1: ACrack\n", "  2: Efflorescence\n", "  3: WConccor\n", "  4: Spalling\n", "  5: Wetspot\n", "  6: Rust\n", "  7: ExposedRebars\n", "\"\"\"\n", "yaml_path = BASE / \"data_colab.yaml\"\n", "yaml_path.write_text(yaml_text)\n", "print(f\"Wrote {yaml_path}\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZjBmGM_lXLzQ", "outputId": "55872390-7d7b-4bb2-be61-bb7b34c4777b"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["BASE=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025\"\n", "echo \"Training images:\";     find \"$BASE/train\" -iregex '.*\\.\\(jpg\\|jpeg\\|png\\|webp\\)' | wc -l\n", "echo \"Validation images:\";   find \"$BASE/val\"   -iregex '.*\\.\\(jpg\\|jpeg\\|png\\|webp\\)' | wc -l\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 106}, "id": "PZTPVnRSZvOo", "outputId": "9eff3603-cf19-438d-e7ac-fd7157f0b7cf"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["BASE=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025\"\n", "\n", "!echo \"Training images:\";     find \"$BASE/train\" -iregex '.*\\.\\(jpg\\|jpeg\\|png\\|webp\\)' | wc -l\n", "!echo \"Validation images:\";   find \"$BASE/val\"   -iregex '.*\\.\\(jpg\\|jpeg\\|png\\|webp\\)' | wc -l\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "3lGVLExjcr31", "outputId": "2f6bf427-76c7-45f0-aa0b-aa60075506e7"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["!yolo task=segment mode=train \\\n", "  model=yolo11m-seg.pt \\\n", "  data=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/data_colab.yaml\" \\\n", "  epochs=250 imgsz=640 batch=-1 \\\n", "  workers=2 persistent_workers=False cache=True \\\n", "  lr0=0.001 lrf=0.01 momentum=0.937 weight_decay=0.0005 \\\n", "  patience=30 warmup_epochs=3 \\\n", "  degrees=30 translate=0.1 scale=0.5 shear=2 perspective=0.0005 \\\n", "  fliplr=0.5 flipud=0.3 hsv_h=0.015 hsv_s=0.7 hsv_v=0.4 \\\n", "  project=\"/content/drive/MyDrive/yolo_runs\" name=\"train_colab_m640\"\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "9vPdl6IxdlPZ", "outputId": "e4d2faa9-bd90-406e-c0f9-d031aec7ade0"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["!yolo task=segment mode=train \\\n", "  model=yolo11m-seg.pt \\\n", "  data=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/data_colab.yaml\" \\\n", "  epochs=250 imgsz=640 batch=-1 \\\n", "  workers=2 cache=True \\\n", "  lr0=0.001 lrf=0.01 momentum=0.937 weight_decay=0.0005 \\\n", "  patience=30 warmup_epochs=3 \\\n", "  degrees=30 translate=0.1 scale=0.5 shear=2 perspective=0.0005 \\\n", "  fliplr=0.5 flipud=0.3 hsv_h=0.015 hsv_s=0.7 hsv_v=0.4 \\\n", "  project=\"/content/drive/MyDrive/yolo_runs\" name=\"train_colab_m640\"\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ae3WxeQiiCyu", "outputId": "98f0640a-d160-44a8-f7cc-61a3d47326c9"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "yNP9m7gwidYp", "outputId": "82391857-ffcf-4db3-9ef0-1be84cb8bdac"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["!yolo predict \\\n", "  model=\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\" \\\n", "  source=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\" \\\n", "  conf=0.4 save=True\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "45MwtApLJmWZ", "outputId": "c97881b3-8fed-463c-a60c-6f6efdb6d4eb"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["!yolo predict \\\n", "  model=\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\" \\\n", "  source=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\" \\\n", "  conf=0.4 save=True \\\n", "  project=\"/content/drive/MyDrive/yolo_runs\" name=\"trial_preds\"\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "kunB5YaqN7J7", "outputId": "e7890818-d8cc-4068-f92e-a59b49e24bbc"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n", "\n", "out_project = \"/content/drive/MyDrive/yolo_runs\"\n", "out_name = \"trial_preds_polygons\"\n", "\n", "results = model.predict(\n", "    source=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\",\n", "    imgsz=640,\n", "    conf=0.4,\n", "    save=True,\n", "    max_det=300,\n", "    project=out_project,\n", "    name=out_name,\n", ")\n", "\n", "print(\"Saved to:\", Path(out_project) / out_name)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "QgFnEiC0Ol3v", "outputId": "94719d8e-8861-42b1-af97-885f15e770c9"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n", "\n", "out_project = \"/content/drive/MyDrive/yolo_runs\"\n", "out_name = \"trial_preds_polygons\"\n", "\n", "results = model.predict(\n", "    source=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\",\n", "    imgsz=640,\n", "    conf=0.6,\n", "    save=True,\n", "    max_det=300,\n", "    project=out_project,\n", "    name=out_name,\n", ")\n", "\n", "print(\"Saved to:\", Path(out_project) / out_name)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "DUD_SAYJP5Cs", "outputId": "7d0df7b5-b88e-40e1-8201-c39efa6a50b3"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n", "\n", "out_project = \"/content/drive/MyDrive/yolo_runs\"\n", "out_name = \"trial_preds_polygons\"\n", "\n", "results = model.predict(\n", "    source=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\",\n", "    imgsz=640,\n", "    conf=0.5,\n", "    save=True,\n", "    max_det=300,\n", "    project=out_project,\n", "    name=out_name,\n", ")\n", "\n", "print(\"Saved to:\", Path(out_project) / out_name)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "6JMTYJocQT1g", "outputId": "1a70a028-857f-472a-a8c0-2421606d617c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n", "\n"], "metadata": {"id": "h8wzncynQ1zs", "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "832fc66b-3af9-4714-9234-11fb91a573f7"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install ultralytics --quiet\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "lI2MTXxxT_pt", "outputId": "6fdbc2b0-11ee-401e-b7d4-ffc7bfe88f91"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "TYvAG5BYUMR5", "outputId": "758e8173-5e98-48d1-ca28-164ee075947e"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n"], "metadata": {"id": "pyR4QYidU62L"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n", "\n", "out_project = \"/content/drive/MyDrive/yolo_runs\"\n", "out_name = \"trial_preds_polygons\"\n", "\n", "results = model.predict(\n", "    source=\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\",\n", "    imgsz=640,\n", "    conf=0.5,\n", "    save=True,\n", "    max_det=300,\n", "    project=out_project,\n", "    name=out_name,\n", ")\n", "\n", "print(\"Saved to:\", Path(out_project) / out_name)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "fXneknSwVCi1", "outputId": "dd9a271a-b408-4ec3-9275-18be4c6247af"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n"], "metadata": {"id": "PQrk9HIJVJkR", "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "512ffbd6-b3b0-4dd6-8a01-2e42aed345a0"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install ultralytics --quiet"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Nwiad7EPMvoJ", "outputId": "0a3ac513-2d38-4a64-ba93-d688fb6e5011"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "DYbgnE6iM5gP", "outputId": "a7ad6c5e-bf67-4417-dc90-ad68097f97e2"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n"], "metadata": {"id": "WckxQBQ2NC1n"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ----- config -----\n", "MODEL = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"\n", "RUN_NAME = \"trial_preds_polygons\"  # results folder: {PROJECT}/{RUN_NAME}/\n", "IMGSZ = 640\n", "CONF = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the text box background\n", "\n", "# ----- run prediction -----\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE, imgsz=IMGSZ, conf=CONF, save=True, max_det=300,\n", "    project=PROJECT, name=RUN_NAME,\n", ")\n", "\n", "# ----- helper to draw a top-left counts box -----\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        return\n", "    # compute background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    # semi-transparent rectangle\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    # text lines\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    cv2.imwrite(str(img_path), img)\n", "\n", "# ----- per-image counting + outputs -----\n", "for res in results:\n", "    save_dir = Path(getattr(res, \"save_dir\", PROJECT)) / RUN_NAME\n", "    out_img = save_dir / Path(res.path).name  # annotated image path\n", "\n", "    # collect class indices from predicted boxes (seg models still have boxes.cls)\n", "    cls_idxs = []\n", "    if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "        cls_tensor = res.boxes.cls\n", "        cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "    counts = Counter(cls_idxs)\n", "    lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "    # write a text file next to the annotated image\n", "    txt_path = save_dir / f\"{Path(res.path).stem}_counts.txt\"\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    # overlay the counts box on the saved annotated image\n", "    overlay_counts_on_image(out_img, lines)\n", "\n", "print(\"Saved to:\", Path(PROJECT) / RUN_NAME)\n", "print(\"✅ Counts overlay added and *_counts.txt files written for each image.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 315}, "id": "OZYO3tvVNmfU", "outputId": "1e3f7ad1-4c00-4095-a68e-9da552730c7a"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"\n", "RUN_NAME = \"trial_preds_polygons\"   # YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPER: draw top-left counts box on the saved image ======\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        return\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    cv2.imwrite(str(img_path), img)\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "for res in results:\n", "    save_dir = Path(res.save_dir)                             # the actual folder YOLO wrote to (e.g., .../trial_preds_polygons5/)\n", "    out_img  = save_dir / Path(res.path).name                 # path to saved annotated image\n", "\n", "    # collect class indices from predicted boxes (seg models also have boxes.cls)\n", "    cls_idxs = []\n", "    if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "        cls_tensor = res.boxes.cls\n", "        cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "    counts = Counter(cls_idxs)\n", "    lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "    # write per-image counts file next to the annotated image\n", "    txt_path = save_dir / f\"{Path(res.path).stem}_counts.txt\"\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    # overlay counts box on the saved annotated image\n", "    overlay_counts_on_image(out_img, lines)\n", "\n", "print(\"✅ Done. Outputs are in:\", Path(results[0].save_dir) if results else Path(PROJECT)/RUN_NAME)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "jQ4L_bA0OMaz", "outputId": "4959aab6-61f1-48d0-9ab9-d7b75b8e4255"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"\n", "RUN_NAME = \"trial_preds_polygons\"   # YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "9-hpMSCqPJBl", "outputId": "79202f5f-bec7-45e7-9cbf-23ce91719c75"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ayuwuopHQSDJ", "outputId": "12aff4ba-3e3c-404b-9b04-116bcdd062d0"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "\n", "# Your trained model\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n", "\n", "# Folder with your test videos\n", "src_dir = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "\n", "# Where to save annotated outputs (in Drive so they persist)\n", "out_project = \"/content/drive/MyDrive/yolo_runs\"\n", "out_name = \"video_preds_polygons\"   # results will go to /content/drive/MyDrive/yolo_runs/video_preds_polygons/\n", "\n", "# Either let Ultralytics handle the whole folder at once...\n", "results = model.predict(\n", "    source=str(src_dir),   # processes all videos/images inside this folder\n", "    imgsz=640,\n", "    conf=0.5,\n", "    save=True,\n", "    max_det=300,\n", "    project=out_project,\n", "    name=out_name,\n", ")\n", "\n", "print(\"Saved to:\", f\"{out_project}/{out_name}\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "-da220JWTImn", "outputId": "8179b026-0f4d-498f-cfc2-f727de7f24ee"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter, defaultdict\n", "import torch\n", "import math\n", "\n", "# ====== CONFIG ======\n", "MODEL     = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "VIDEO_DIR = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "PROJECT   = \"/content/drive/MyDrive/yolo_runs\"\n", "RUN_NAME  = \"video_preds_polygons_tracked\"   # YOLO may append a number if exists\n", "IMGSZ     = 640\n", "CONF      = 0.5\n", "TRACKER   = \"bytetrack.yaml\"  # robust default tracker (ships with Ultralytics)\n", "\n", "# Process only typical video extensions\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ====== LOAD MODEL ======\n", "model = YOLO(MODEL)\n", "\n", "# ====== LOOP VIDEOS ======\n", "videos = [p for p in VIDEO_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    print(f\"No videos found in {VIDEO_DIR}\")\n", "else:\n", "    print(f\"Found {len(videos)} video(s) in {VIDEO_DIR}\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ Tracking: {vf.name}\")\n", "    # Run tracker (returns per-frame Results)\n", "    vid_results = model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ,\n", "        conf=CONF,\n", "        save=True,\n", "        tracker=TRACKER,\n", "        project=PROJECT,\n", "        name=RUN_NAME,   # YOLO may auto-append a number; we’ll read save_dir below\n", "        verbose=False\n", "    )\n", "\n", "    if not vid_results:\n", "        print(f\"  ⚠️ No results returned for {vf.name}\")\n", "        continue\n", "\n", "    # Where outputs were saved for this video\n", "    save_dir = Path(vid_results[0].save_dir)\n", "    names = vid_results[0].names  # class names mapping\n", "\n", "    # === Count unique tracks per class over the entire video ===\n", "    # For each class, keep a set of track IDs (stable across frames)\n", "    unique_ids_per_class = defaultdict(set)\n", "    # Fallback counter if no IDs are produced (rare, but handle it)\n", "    fallback_new_object_counts = Counter()\n", "\n", "    had_ids = False\n", "\n", "    for res in vid_results:\n", "        # If tracker assigned IDs, we get them in res.boxes.id (Tensor of shape [N])\n", "        if getattr(res, \"boxes\", None) is not None:\n", "            cls_t = getattr(res.boxes, \"cls\", None)\n", "            id_t  = getattr(res.boxes, \"id\", None)  # <-- present when tracking works\n", "\n", "            if id_t is not None:\n", "                had_ids = True\n", "                # Move to CPU lists\n", "                cls_list = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "                id_list  = id_t.detach().cpu().tolist()  if isinstance(id_t, torch.Tensor)  else list(id_t or [])\n", "\n", "                for c, tid in zip(cls_list, id_list):\n", "                    # Some trackers can output -1 or NaN before stable assignment; ignore those\n", "                    if tid is None or (isinstance(tid, float) and (math.isnan(tid) or tid < 0)) or (isinstance(tid, (int, float)) and tid < 0):\n", "                        continue\n", "                    c = int(c)\n", "                    tid = int(tid)\n", "                    unique_ids_per_class[c].add(tid)\n", "            else:\n", "                # Fallback if tracker didn't attach IDs: very conservative\n", "                # (Counts per frame, but we will dedupe poorly; recommend using IDs)\n", "                if cls_t is not None:\n", "                    cls_list = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "                    for c in cls_list:\n", "                        fallback_new_object_counts[int(c)] += 1\n", "\n", "    # Build lines for output\n", "    if had_ids:\n", "        # Count unique track IDs per class → the robust, non-duplicated counts\n", "        lines = [f\"{names[c]}: {len(ids)}\" for c, ids in sorted(unique_ids_per_class.items()) if len(ids) > 0]\n", "        if not lines:\n", "            lines = [\"No detections\"]\n", "    else:\n", "        # Fallback if tracker IDs weren’t produced (shouldn’t happen with bytetrack)\n", "        lines = [f\"{names[c]}: {fallback_new_object_counts[c]}\" for c in sorted(fallback_new_object_counts.keys())] or [\"No detections\"]\n", "        lines.insert(0, \"(fallback: tracker IDs unavailable)\")\n", "\n", "    # Write one summary counts file per video, next to the saved video\n", "    txt_path = save_dir / f\"{vf.stem}_counts.txt\"\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Tracked video outputs and *_counts.txt files are inside:\")\n", "print(Path(PROJECT) / RUN_NAME, \"(or with an auto-appended number if re-run)\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 686}, "id": "5O_ymMuDYkgd", "outputId": "fc70f6f9-e29c-4baf-c52e-275064858395"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install -q \"lap>=0.5.12\"\n"], "metadata": {"id": "qZ_VONGIcu3l"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import torch, math\n", "\n", "# ==== CONFIG ====\n", "MODEL     = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "VIDEO_DIR = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "PROJECT   = \"/content/drive/MyDrive/yolo_runs\"\n", "RUN_NAME  = \"video_preds_polygons_tracked\"  # YOLO may append a number if it exists\n", "IMGSZ     = 640\n", "CONF      = 0.5\n", "TRACKER   = \"bytetrack.yaml\"  # robust default\n", "\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ==== LOAD MODEL ====\n", "model = YOLO(MODEL)\n", "\n", "videos = [p for p in VIDEO_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "print(f\"Found {len(videos)} video(s) in {VIDEO_DIR}\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ Tracking: {vf.name}\")\n", "\n", "    # Collect unique track IDs per class over the entire video\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    save_dir = None\n", "    had_ids = False\n", "\n", "    # stream=True avoids storing all frames in memory\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        save=True,\n", "        project=PROJECT,\n", "        name=RUN_NAME,\n", "        stream=True,\n", "        verbose=False,\n", "    ):\n", "        if save_dir is None:\n", "            save_dir = Path(res.save_dir)\n", "            names = res.names\n", "\n", "        if getattr(res, \"boxes\", None) is None:\n", "            continue\n", "\n", "        cls_t = getattr(res.boxes, \"cls\", None)\n", "        id_t  = getattr(res.boxes, \"id\",  None)  # present when tracker is active\n", "\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            # ignore invalid IDs\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "    if save_dir is None:\n", "        print(\"  ⚠️ No output save_dir returned; skipping counts file.\")\n", "        continue\n", "\n", "    # Build lines (unique track counts per class)\n", "    if had_ids:\n", "        lines = [f\"{names[c]}: {len(ids)}\" for c, ids in sorted(unique_ids_per_class.items()) if len(ids) > 0]\n", "        if not lines:\n", "            lines = [\"No detections\"]\n", "    else:\n", "        lines = [\"(fallback) No tracker IDs produced\", \"No detections\"]\n", "\n", "    # Write summary counts next to the saved video\n", "    txt_path = save_dir / f\"{vf.stem}_counts.txt\"\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Outputs (videos + *_counts.txt) are in:\", Path(PROJECT) / RUN_NAME, \"(or with an auto-appended number)\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 408}, "id": "6pkHWNirdWEe", "outputId": "bfdf5bc6-5a61-4174-d010-4ac76d5af393"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import torch, math\n", "\n", "# ==== CONFIG ====\n", "MODEL     = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "VIDEO_DIR = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "PROJECT   = \"/content/drive/MyDrive/yolo_runs\"\n", "RUN_NAME  = \"video_preds_polygons_tracked\"  # YOLO may append a number if it exists\n", "IMGSZ     = 640\n", "CONF      = 0.5\n", "TRACKER   = \"bytetrack.yaml\"  # robust default\n", "\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ==== LOAD MODEL ====\n", "model = YOLO(MODEL)\n", "\n", "videos = [p for p in VIDEO_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "print(f\"Found {len(videos)} video(s) in {VIDEO_DIR}\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ Tracking: {vf.name}\")\n", "\n", "    # Collect unique track IDs per class over the entire video\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    save_dir = None\n", "    had_ids = False\n", "\n", "    # stream=True avoids storing all frames in memory\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        save=True,\n", "        project=PROJECT,\n", "        name=RUN_NAME,\n", "        stream=True,\n", "        verbose=False,\n", "    ):\n", "        if save_dir is None:\n", "            save_dir = Path(res.save_dir)\n", "            names = res.names\n", "\n", "        if getattr(res, \"boxes\", None) is None:\n", "            continue\n", "\n", "        cls_t = getattr(res.boxes, \"cls\", None)\n", "        id_t  = getattr(res.boxes, \"id\",  None)  # present when tracker is active\n", "\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            # ignore invalid IDs\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "    if save_dir is None:\n", "        print(\"  ⚠️ No output save_dir returned; skipping counts file.\")\n", "        continue\n", "\n", "    # Build lines (unique track counts per class)\n", "    if had_ids:\n", "        lines = [f\"{names[c]}: {len(ids)}\" for c, ids in sorted(unique_ids_per_class.items()) if len(ids) > 0]\n", "        if not lines:\n", "            lines = [\"No detections\"]\n", "    else:\n", "        lines = [\"(fallback) No tracker IDs produced\", \"No detections\"]\n", "\n", "    # Write summary counts next to the saved video\n", "    txt_path = save_dir / f\"{vf.stem}_counts.txt\"\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Outputs (videos + *_counts.txt) are in:\", Path(PROJECT) / RUN_NAME, \"(or with an auto-appended number)\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 408}, "id": "FaHzGepJdb5d", "outputId": "d69ad6f8-f194-4b2c-ef25-305e5ed384a5"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# If you still get 'lap' warnings, ensure it's installed once:\n", "# %pip install -q \"lap>=0.5.12\"\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import shutil, os, math, torch\n", "\n", "# ===== CONFIG =====\n", "MODEL      = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "DRIVE_VIDS = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "LOCAL_VIDS = Path(\"/content/tmp_videos\")        # process from local disk\n", "LOCAL_OUT  = Path(\"/content/track_runs\")        # write results locally\n", "DRIVE_OUT  = Path(\"/content/drive/MyDrive/yolo_runs\")  # final destination in Drive\n", "RUN_NAME   = \"video_preds_polygons_tracked\"     # Ultralytics may append a number\n", "IMGSZ      = 640\n", "CONF       = 0.5\n", "TRACKER    = \"bytetrack.yaml\"\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "PRINT_EVERY = 25           # print a progress line every N frames\n", "USE_FP16    = True         # half precision\n", "VID_STRIDE  = 1            # set to 2 to skip every other frame (faster, slightly less accurate)\n", "\n", "# ===== PREP LOCAL INPUT =====\n", "LOCAL_VIDS.mkdir(parents=True, exist_ok=True)\n", "# copy videos from Drive to local (overwrite if changed)\n", "src_videos = [p for p in DRIVE_VIDS.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not src_videos:\n", "    raise SystemExit(f\"No videos found in {DRIVE_VIDS}\")\n", "\n", "for p in src_videos:\n", "    dest = LOCAL_VIDS / p.name\n", "    if not dest.exists():\n", "        shutil.copy2(p, dest)\n", "\n", "print(f\"Processing {len(src_videos)} video(s) from {LOCAL_VIDS}\")\n", "\n", "# ===== RUN TRACKING PER VIDEO =====\n", "model = YOLO(MODEL)\n", "\n", "for vf in src_videos:\n", "    local_vf = LOCAL_VIDS / vf.name\n", "    print(f\"\\n▶ Tracking: {local_vf.name}\")\n", "\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    save_dir = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True: yields one Results per frame; verbose=True prints Ultralytics logs\n", "    for res in model.track(\n", "        source=str(local_vf),\n", "        device=0,\n", "        imgsz=IMGSZ,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        save=True,\n", "        project=str(LOCAL_OUT),\n", "        name=RUN_NAME,\n", "        stream=True,\n", "        verbose=True,\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE,\n", "    ):\n", "        # first frame: capture output dir and names\n", "        if save_dir is None:\n", "            save_dir = Path(res.save_dir)\n", "            names = res.names\n", "            print(f\"Output will be in: {save_dir}\")\n", "\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  • processed frame {frame_idx}\")\n", "\n", "        if getattr(res, \"boxes\", None) is None:\n", "            continue\n", "        cls_t = getattr(res.boxes, \"cls\", None)\n", "        id_t  = getattr(res.boxes, \"id\",  None)\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None or (isinstance(tid, float) and (math.isnan(tid) or tid < 0)) or (isinstance(tid, (int, float)) and tid < 0):\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "    if save_dir is None:\n", "        print(\"  ⚠️ No frames produced; skipping.\")\n", "        continue\n", "\n", "    # build counts text (unique track IDs per class)\n", "    if had_ids:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "        if not lines:\n", "            lines = [\"No detections\"]\n", "    else:\n", "        lines = [\"(fallback) No tracker IDs produced\", \"No detections\"]\n", "\n", "    txt_path = save_dir / f\"{vf.stem}_counts.txt\"\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "# ===== MOVE RESULT FOLDER BACK TO DRIVE =====\n", "# Find the actual run folder (Ultralytics may have appended a number)\n", "made = [p for p in LOCAL_OUT.iterdir() if p.is_dir() and p.name.startswith(RUN_NAME)]\n", "for folder in made:\n", "    dest = DRIVE_OUT / folder.name\n", "    # move or merge into Drive\n", "    if dest.exists():\n", "        # if already exists, append a suffix to avoid overwrite\n", "        i = 2\n", "        while (DRIVE_OUT / f\"{folder.name}_{i}\").exists():\n", "            i += 1\n", "        dest = DRIVE_OUT / f\"{folder.name}_{i}\"\n", "    shutil.move(str(folder), str(dest))\n", "    print(f\"📦 Moved results to Drive: {dest}\")\n", "\n", "print(\"\\n🎬 Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "pypGrqKjdwEF", "outputId": "200098a6-60d8-4b0c-c022-fbf66e7ab8a7"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "reM90KlUfkfe", "outputId": "7ed054aa-26ce-4767-a6e7-c8bd8e244d51"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "H_WlG1vrgsRK", "outputId": "a39a143b-b7be-4b80-9993-3bd9233aaccc"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "\n", "# Your trained model\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n", "\n", "# Folder with your test videos\n", "src_dir = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "\n", "# Where to save annotated outputs (in Drive so they persist)\n", "out_project = \"/content/drive/MyDrive/yolo_runs\"\n", "out_name = \"video_preds_polygons\"   # results will go to /content/drive/MyDrive/yolo_runs/video_preds_polygons/\n", "\n", "# Either let Ultralytics handle the whole folder at once...\n", "results = model.predict(\n", "    source=str(src_dir),   # processes all videos/images inside this folder\n", "    imgsz=640,\n", "    conf=0.5,\n", "    save=True,\n", "    max_det=300,\n", "    project=out_project,\n", "    name=out_name,\n", ")\n", "\n", "print(\"Saved to:\", f\"{out_project}/{out_name}\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "A_wP7VaBgyA9", "outputId": "f63c82e7-1eb1-4f34-c252-526beff5f254"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "2_kMW8emg30e", "outputId": "273a96d8-d21a-4800-fdc3-828b81f69d42"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# If you still see a 'lap' warning once, run:\n", "# %pip install -q \"lap>=0.5.12\"\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# === CONFIG ===\n", "MODEL     = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "VIDEO_DIR = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "PROJECT   = \"/content/drive/MyDrive/yolo_runs\"           # only for placing the *_counts.txt\n", "RUN_NAME  = \"video_counts_only_tracked\"                  # folder will be created under PROJECT\n", "IMGSZ     = 512                                          # smaller = less compute\n", "CONF      = 0.5\n", "TRACKER   = \"bytetrack.yaml\"\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "USE_FP16   = True\n", "VID_STRIDE = 2                                           # process every 2nd frame (2x faster)\n", "PRINT_EVERY = 50\n", "\n", "model = YOLO(MODEL)\n", "videos = [p for p in VIDEO_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "print(f\"Found {len(videos)} video(s) in {VIDEO_DIR}\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ Counting (no video saved): {vf.name}\")\n", "\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # <— do NOT save annotated frames\n", "        stream=True,                # <— generator, no big buffering\n", "        stream_buffer=False,        # <— don’t accumulate past results\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE,\n", "        verbose=False,\n", "        project=PROJECT,            # needed only so we can place a folder for counts\n", "        name=RUN_NAME,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # write counts file to a stable folder\n", "    out_dir = Path(PROJECT) / RUN_NAME\n", "    out_dir.mkdir(parents=True, exist_ok=True)\n", "    txt_path = out_dir / f\"{vf.stem}_counts.txt\"\n", "\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Counts are in:\", Path(PROJECT) / RUN_NAME)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "hGmCmtVVinf8", "outputId": "ca3b559a-3999-4d07-d931-30bbec9c416e"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE-CELL: unique-ID counts per video + save annotated videos to the same folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL      = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR    = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "PROJECT    = \"/content/drive/MyDrive/yolo_runs\"      # parent folder\n", "RUN_NAME   = \"video_preds_polygons\"                  # <— both counts and videos go here\n", "IMGSZ_CNT  = 512                                     # counting pass (lighter)\n", "IMGSZ_VID  = 640                                     # saved video pass\n", "CONF       = 0.5\n", "TRACKER    = \"bytetrack.yaml\"\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "USE_FP16   = True\n", "VID_STRIDE_CNT = 2                                   # faster counting\n", "VID_STRIDE_VID = 1                                   # best quality for saved videos\n", "PRINT_EVERY = 50\n", "\n", "# Ensure source videos exist\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# Create the shared output dir (counts + videos will live here)\n", "run_dir = Path(PROJECT) / RUN_NAME\n", "run_dir.mkdir(parents=True, exist_ok=True)\n", "\n", "# ================= PASS 1: COUNT UNIQUE IDS (RAM-SAFE, NO VIDEO SAVED) =================\n", "model = YOLO(MODEL)\n", "print(f\"Counting unique defects (no video saving) for {len(videos)} video(s)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                # <— no annotated frames saved\n", "        stream=True,               # generator\n", "        stream_buffer=False,       # don’t buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # write per-video counts file into the shared run folder\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines: print(\"   \", L)\n", "\n", "# ================= PASS 2: SAVE ANNOTATED VIDEOS (SAME FOLDER) =================\n", "print(f\"\\nSaving annotated videos into the same folder: {run_dir}\")\n", "_ = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,      # <— same folder as counts\n", "    exist_ok=True,      # <— reuse the folder, don’t make ..._2, ..._3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "print(\"\\n✅ All done. Counts and videos are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "nd2l7nvyiytx", "outputId": "70bbab4a-e0a5-4396-b90c-a27aa438dc6c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE-CELL: unique-ID counts per video + save annotated videos to the same folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL      = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR    = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "PROJECT    = \"/content/drive/MyDrive/yolo_runs\"      # parent folder\n", "RUN_NAME   = \"video_preds_polygons\"                  # <— both counts and videos go here\n", "IMGSZ_CNT  = 512                                     # counting pass (lighter)\n", "IMGSZ_VID  = 640                                     # saved video pass\n", "CONF       = 0.5\n", "TRACKER    = \"bytetrack.yaml\"\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "USE_FP16   = True\n", "VID_STRIDE_CNT = 2                                   # faster counting\n", "VID_STRIDE_VID = 1                                   # best quality for saved videos\n", "PRINT_EVERY = 50\n", "\n", "# Ensure source videos exist\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# Create the shared output dir (counts + videos will live here)\n", "run_dir = Path(PROJECT) / RUN_NAME\n", "run_dir.mkdir(parents=True, exist_ok=True)\n", "\n", "# ================= PASS 1: COUNT UNIQUE IDS (RAM-SAFE, NO VIDEO SAVED) =================\n", "model = YOLO(MODEL)\n", "print(f\"Counting unique defects (no video saving) for {len(videos)} video(s)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                # <— no annotated frames saved\n", "        stream=True,               # generator\n", "        stream_buffer=False,       # don’t buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # write per-video counts file into the shared run folder\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines: print(\"   \", L)\n", "\n", "# ================= PASS 2: SAVE ANNOTATED VIDEOS (SAME FOLDER) =================\n", "print(f\"\\nSaving annotated videos into the same folder: {run_dir}\")\n", "_ = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,      # <— same folder as counts\n", "    exist_ok=True,      # <— reuse the folder, don’t make ..._2, ..._3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "print(\"\\n✅ All done. Counts and videos are in:\", run_dir)\n", "\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "hWuovy0zkTQo", "outputId": "35e83096-72e7-472b-df44-9bb402d41804"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE CELL: save annotated videos AND write unique-ID counts, with auto-numbered run folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"    # parent folder for runs\n", "RUN_NAME    = \"video_preds_polygons\"                # base name (YOLO will append numbers automatically)\n", "CONF        = 0.5\n", "\n", "# Video saving pass (prettier output)\n", "IMGSZ_VID   = 640\n", "VID_STRIDE_VID = 1\n", "\n", "# Counting pass (RAM-safe + faster)\n", "IMGSZ_CNT   = 512\n", "VID_STRIDE_CNT = 2\n", "USE_FP16    = True\n", "TRACKER     = \"bytetrack.yaml\"\n", "PRINT_EVERY = 50\n", "VIDEO_EXTS  = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ================= CHECK SOURCE =================\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# ================= LOAD MODEL =================\n", "model = YOLO(MODEL)\n", "\n", "# ================= PASS 1: SAVE ANNOTATED VIDEOS =================\n", "print(\"Saving annotated videos (YOLO will auto-append run folder number if needed)...\")\n", "pred_results = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,     # <-- no exist_ok, so YOLO creates video_preds_polygons, ...2, ...3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "# Get the actual auto-numbered folder YOLO just created\n", "if not pred_results:\n", "    raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir)\n", "print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "# ================= PASS 2: COUNT UNIQUE DEFECTS PER VIDEO =================\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # DO NOT save frames in counting pass\n", "        stream=True,                # generator\n", "        stream_buffer=False,        # don't buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs present when tracking works\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write per-video counts file into the SAME run_dir as the videos\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ziNV6kh4kw33", "outputId": "7089a605-0c95-4fca-dc6e-580ff5f20c40"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n"], "metadata": {"id": "KloYBg04mFB1", "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "fe9446d5-a5cb-459a-e7ed-172dbe48df1a"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install ultralytics --quiet"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "pFkbeO0GUKlZ", "outputId": "364498dd-0cb7-4e2f-8975-3f33fdf80892"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "1nZND9r9VEJb", "outputId": "ae2a6024-9d25-40c1-d75c-35327a91344c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n"], "metadata": {"id": "Qlo0BMQ0VSKh"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE CELL: save annotated videos AND write unique-ID counts, with auto-numbered run folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"    # parent folder for runs\n", "RUN_NAME    = \"video_preds_polygons\"                # base name (YOLO will append numbers automatically)\n", "CONF        = 0.5\n", "\n", "# Video saving pass (prettier output)\n", "IMGSZ_VID   = 640\n", "VID_STRIDE_VID = 1\n", "\n", "# Counting pass (RAM-safe + faster)\n", "IMGSZ_CNT   = 640\n", "VID_STRIDE_CNT = 2\n", "USE_FP16    = True\n", "TRACKER     = \"bytetrack.yaml\"\n", "PRINT_EVERY = 50\n", "VIDEO_EXTS  = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ================= CHECK SOURCE =================\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# ================= LOAD MODEL =================\n", "model = YOLO(MODEL)\n", "\n", "# ================= PASS 1: SAVE ANNOTATED VIDEOS =================\n", "print(\"Saving annotated videos (YOLO will auto-append run folder number if needed)...\")\n", "pred_results = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,     # <-- no exist_ok, so YOLO creates video_preds_polygons, ...2, ...3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "# Get the actual auto-numbered folder YOLO just created\n", "if not pred_results:\n", "    raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir)\n", "print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "# ================= PASS 2: COUNT UNIQUE DEFECTS PER VIDEO =================\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # DO NOT save frames in counting pass\n", "        stream=True,                # generator\n", "        stream_buffer=False,        # don't buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs present when tracking works\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write per-video counts file into the SAME run_dir as the videos\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "DY_2PSexVcGZ", "outputId": "99a83a2c-e933-4007-f2cd-0956eaa94f0b"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE CELL: save annotated videos AND write unique-ID counts, with auto-numbered run folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"    # parent folder for runs\n", "RUN_NAME    = \"video_preds_polygons\"                # base name (YOLO will append numbers automatically)\n", "CONF        = 0.5\n", "\n", "# Video saving pass (prettier output)\n", "IMGSZ_VID   = 640\n", "VID_STRIDE_VID = 1\n", "\n", "# Counting pass (RAM-safe + faster)\n", "IMGSZ_CNT   = 640\n", "VID_STRIDE_CNT = 2\n", "USE_FP16    = True\n", "TRACKER     = \"bytetrack.yaml\"\n", "PRINT_EVERY = 50\n", "VIDEO_EXTS  = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ================= CHECK SOURCE =================\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# ================= LOAD MODEL =================\n", "model = YOLO(MODEL)\n", "\n", "# ================= PASS 1: SAVE ANNOTATED VIDEOS =================\n", "print(\"Saving annotated videos (YOLO will auto-append run folder number if needed)...\")\n", "pred_results = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,     # <-- no exist_ok, so YOLO creates video_preds_polygons, ...2, ...3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "# Get the actual auto-numbered folder YOLO just created\n", "if not pred_results:\n", "    raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir)\n", "print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "# ================= PASS 2: COUNT UNIQUE DEFECTS PER VIDEO =================\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # DO NOT save frames in counting pass\n", "        stream=True,                # generator\n", "        stream_buffer=False,        # don't buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs present when tracking works\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write per-video counts file into the SAME run_dir as the videos\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "C0yOT1vyWDEm", "outputId": "e7b1c37c-e62d-48b2-8aed-4fe3d092e133"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE CELL: save annotated videos AND write unique-ID counts, with auto-numbered run folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"    # parent folder for runs\n", "RUN_NAME    = \"video_preds_polygons\"                # base name (YOLO will append numbers automatically)\n", "CONF        = 0.5\n", "\n", "# Video saving pass (prettier output)\n", "IMGSZ_VID   = 640\n", "VID_STRIDE_VID = 1\n", "\n", "# Counting pass (RAM-safe + faster)\n", "IMGSZ_CNT   = 640\n", "VID_STRIDE_CNT = 2\n", "USE_FP16    = True\n", "TRACKER     = \"bytetrack.yaml\"\n", "PRINT_EVERY = 50\n", "VIDEO_EXTS  = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ================= CHECK SOURCE =================\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# ================= LOAD MODEL =================\n", "model = YOLO(MODEL)\n", "\n", "# ================= PASS 1: SAVE ANNOTATED VIDEOS =================\n", "print(\"Saving annotated videos (YOLO will auto-append run folder number if needed)...\")\n", "pred_results = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,     # <-- no exist_ok, so YOLO creates video_preds_polygons, ...2, ...3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "# Get the actual auto-numbered folder YOLO just created\n", "if not pred_results:\n", "    raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir)\n", "print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "# ================= PASS 2: COUNT UNIQUE DEFECTS PER VIDEO =================\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # DO NOT save frames in counting pass\n", "        stream=True,                # generator\n", "        stream_buffer=False,        # don't buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs present when tracking works\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write per-video counts file into the SAME run_dir as the videos\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "xOx_KaWuZZ3N", "outputId": "a8f03beb-7adb-4ef1-97c6-9ecf010d0e46"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE CELL: save annotated videos AND write unique-ID counts, with auto-numbered run folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"    # parent folder for runs\n", "RUN_NAME    = \"video_preds_polygons\"                # base name (YOLO will append numbers automatically)\n", "CONF        = 0.5\n", "\n", "# Video saving pass (prettier output)\n", "IMGSZ_VID   = 640\n", "VID_STRIDE_VID = 1\n", "\n", "# Counting pass (RAM-safe + faster)\n", "IMGSZ_CNT   = 640\n", "VID_STRIDE_CNT = 2\n", "USE_FP16    = True\n", "TRACKER     = \"bytetrack.yaml\"\n", "PRINT_EVERY = 50\n", "VIDEO_EXTS  = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ================= CHECK SOURCE =================\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# ================= LOAD MODEL =================\n", "model = YOLO(MODEL)\n", "\n", "# ================= PASS 1: SAVE ANNOTATED VIDEOS =================\n", "print(\"Saving annotated videos (YOLO will auto-append run folder number if needed)...\")\n", "pred_results = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,     # <-- no exist_ok, so YOLO creates video_preds_polygons, ...2, ...3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "# Get the actual auto-numbered folder YOLO just created\n", "if not pred_results:\n", "    raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir)\n", "print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "# ================= PASS 2: COUNT UNIQUE DEFECTS PER VIDEO =================\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # DO NOT save frames in counting pass\n", "        stream=True,                # generator\n", "        stream_buffer=False,        # don't buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs present when tracking works\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write per-video counts file into the SAME run_dir as the videos\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "id": "S_-xK4UQdboh", "outputId": "130f563c-1818-4b35-9721-e888f3b477ea"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Z24WeUI4hwKa", "outputId": "b658d483-a997-4728-b339-2f51f2bec18c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE CELL: save annotated videos AND write unique-ID counts, with auto-numbered run folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"    # parent folder for runs\n", "RUN_NAME    = \"video_preds_polygons\"                # base name (YOLO will append numbers automatically)\n", "CONF        = 0.5\n", "\n", "# Video saving pass (prettier output)\n", "IMGSZ_VID   = 640\n", "VID_STRIDE_VID = 1\n", "\n", "# Counting pass (RAM-safe + faster)\n", "IMGSZ_CNT   = 640\n", "VID_STRIDE_CNT = 2\n", "USE_FP16    = True\n", "TRACKER     = \"bytetrack.yaml\"\n", "PRINT_EVERY = 50\n", "VIDEO_EXTS  = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ================= CHECK SOURCE =================\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# ================= LOAD MODEL =================\n", "model = YOLO(MODEL)\n", "\n", "# ================= PASS 1: SAVE ANNOTATED VIDEOS =================\n", "print(\"Saving annotated videos (YOLO will auto-append run folder number if needed)...\")\n", "pred_results = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,     # <-- no exist_ok, so YOLO creates video_preds_polygons, ...2, ...3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "# Get the actual auto-numbered folder YOLO just created\n", "if not pred_results:\n", "    raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir)\n", "print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "# ================= PASS 2: COUNT UNIQUE DEFECTS PER VIDEO =================\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # DO NOT save frames in counting pass\n", "        stream=True,                # generator\n", "        stream_buffer=False,        # don't buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs present when tracking works\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write per-video counts file into the SAME run_dir as the videos\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4nKu64xziv-P", "outputId": "8ad0afce-b758-4439-e50e-5858b68eba74"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === ONE CELL: per-video save (local) + unique-ID counts + move to Drive (auto-numbered folders) ===\n", "# Tip: if you ever see a 'lap' requirement warning, run once:  %pip install -q \"lap>=0.5.12\"\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import shutil, math, torch, gc\n", "\n", "# ---------------- CONFIG ----------------\n", "MODEL = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "\n", "# Source videos in Drive\n", "SRC_DIR = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# Where final results should live (in Drive)\n", "DRIVE_PROJECT = Path(\"/content/drive/MyDrive/yolo_runs\")\n", "RUN_NAME = \"video_preds_polygons\"  # YOLO will auto-append numbers per video: ...,_2,_3,...\n", "\n", "# Local temp folder to avoid Drive I/O during inference (MUCH more stable)\n", "LOCAL_PROJECT = Path(\"/content/vid_tmp\")\n", "\n", "# Predict (video saving) settings — keep these modest to avoid RAM spikes\n", "IMGSZ_VID = 640        # use 640 if you prefer higher quality and have headroom\n", "VID_STRIDE_VID = 2     # 2x faster & lighter (process every other frame)\n", "CONF = 0.5\n", "USE_FP16 = True\n", "RETINA_MASKS = False   # lighter mask drawing\n", "VERBOSE_PRED = False   # don't spam per-frame logs\n", "\n", "# Tracking (counting) settings — RAM-safe\n", "IMGSZ_CNT = 640\n", "VID_STRIDE_CNT = 2\n", "TRACKER = \"bytetrack.yaml\"\n", "PRINT_EVERY = 100      # progress heartbeat\n", "\n", "# -------------- PREP --------------\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "LOCAL_PROJECT.mkdir(parents=True, exist_ok=True)\n", "DRIVE_PROJECT.mkdir(parents=True, exist_ok=True)\n", "\n", "model = YOLO(MODEL)\n", "\n", "for vf in videos:\n", "    print(f\"\\n==================== {vf.name} ====================\")\n", "\n", "    # ---------- PASS A: SAVE ANNOTATED VIDEO LOCALLY ----------\n", "    print(\"• Saving annotated video locally...\")\n", "    preds = model.predict(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_VID,\n", "        conf=CONF,\n", "        save=True,\n", "        project=str(LOCAL_PROJECT),\n", "        name=RUN_NAME,          # no exist_ok → YOLO auto-numbers per video\n", "        vid_stride=VID_STRIDE_VID,\n", "        half=USE_FP16,\n", "        retina_masks=RETINA_MASKS,\n", "        verbose=VERBOSE_PRED,\n", "        device=0,\n", "    )\n", "    if not preds:\n", "        print(\"  ⚠️ No prediction results; skipping counts and move.\")\n", "        continue\n", "\n", "    # The auto-numbered folder for THIS video (e.g., /content/vid_tmp/video_preds_polygons3)\n", "    out_dir_local = Path(preds[0].save_dir)\n", "    print(\"  Local run dir:\", out_dir_local)\n", "\n", "    # ---------- PASS B: COUNT UNIQUE DEFECTS (NO VIDEO SAVED) ----------\n", "    print(\"• Counting unique defects with tracking (no saving)...\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,              # do NOT save frames here\n", "        stream=True,             # generator\n", "        stream_buffer=False,     # don't hold old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"   processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy\n", "        del res\n", "        if frame_idx % 200 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write counts file into the SAME local run folder as the video\n", "    txt_path_local = out_dir_local / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path_local, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "    print(\"  ✅ Wrote counts:\", txt_path_local)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "    # ---------- MOVE THIS VIDEO'S FOLDER TO DRIVE ----------\n", "    dest = DRIVE_PROJECT / out_dir_local.name  # keep the auto-numbered folder name\n", "    if dest.exists():\n", "        # extremely rare; if exists, add suffix\n", "        i = 2\n", "        while (DRIVE_PROJECT / f\"{out_dir_local.name}_{i}\").exists():\n", "            i += 1\n", "        dest = DRIVE_PROJECT / f\"{out_dir_local.name}_{i}\"\n", "\n", "    shutil.move(str(out_dir_local), str(dest))\n", "    print(\"📦 Moved results to Drive:\", dest)\n", "\n", "print(\"\\n✅ Done. All per-video folders (annotated video + *_counts.txt) are under:\", DRIVE_PROJECT)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 599}, "id": "yxU_qG5eiy58", "outputId": "60e33715-12a8-4f13-aa04-a9d0e588fe60"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "MOhyNIhQmako", "outputId": "2d4f0ff6-4fbc-4920-9ae2-cb99c94a1516"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === ONE CELL: per-video save (local) + unique-ID counts + move to Drive (auto-numbered folders) ===\n", "# Tip: if you ever see a 'lap' requirement warning, run once:  %pip install -q \"lap>=0.5.12\"\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import shutil, math, torch, gc\n", "\n", "# ---------------- CONFIG ----------------\n", "MODEL = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "\n", "# Source videos in Drive\n", "SRC_DIR = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# Where final results should live (in Drive)\n", "DRIVE_PROJECT = Path(\"/content/drive/MyDrive/yolo_runs\")\n", "RUN_NAME = \"video_preds_polygons\"  # YOLO will auto-append numbers per video: ...,_2,_3,...\n", "\n", "# Local temp folder to avoid Drive I/O during inference (MUCH more stable)\n", "LOCAL_PROJECT = Path(\"/content/vid_tmp\")\n", "\n", "# Predict (video saving) settings — keep these modest to avoid RAM spikes\n", "IMGSZ_VID = 640        # use 640 if you prefer higher quality and have headroom\n", "VID_STRIDE_VID = 2     # 2x faster & lighter (process every other frame)\n", "CONF = 0.5\n", "USE_FP16 = True\n", "RETINA_MASKS = False   # lighter mask drawing\n", "VERBOSE_PRED = False   # don't spam per-frame logs\n", "\n", "# Tracking (counting) settings — RAM-safe\n", "IMGSZ_CNT = 640\n", "VID_STRIDE_CNT = 2\n", "TRACKER = \"bytetrack.yaml\"\n", "PRINT_EVERY = 100      # progress heartbeat\n", "\n", "# -------------- PREP --------------\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "LOCAL_PROJECT.mkdir(parents=True, exist_ok=True)\n", "DRIVE_PROJECT.mkdir(parents=True, exist_ok=True)\n", "\n", "model = YOLO(MODEL)\n", "\n", "for vf in videos:\n", "    print(f\"\\n==================== {vf.name} ====================\")\n", "\n", "    # ---------- PASS A: SAVE ANNOTATED VIDEO LOCALLY ----------\n", "    print(\"• Saving annotated video locally...\")\n", "    preds = model.predict(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_VID,\n", "        conf=CONF,\n", "        save=True,\n", "        project=str(LOCAL_PROJECT),\n", "        name=RUN_NAME,          # no exist_ok → YOLO auto-numbers per video\n", "        vid_stride=VID_STRIDE_VID,\n", "        half=USE_FP16,\n", "        retina_masks=RETINA_MASKS,\n", "        verbose=VERBOSE_PRED,\n", "        device=0,\n", "    )\n", "    if not preds:\n", "        print(\"  ⚠️ No prediction results; skipping counts and move.\")\n", "        continue\n", "\n", "    # The auto-numbered folder for THIS video (e.g., /content/vid_tmp/video_preds_polygons3)\n", "    out_dir_local = Path(preds[0].save_dir)\n", "    print(\"  Local run dir:\", out_dir_local)\n", "\n", "    # ---------- PASS B: COUNT UNIQUE DEFECTS (NO VIDEO SAVED) ----------\n", "    print(\"• Counting unique defects with tracking (no saving)...\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,              # do NOT save frames here\n", "        stream=True,             # generator\n", "        stream_buffer=False,     # don't hold old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"   processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy\n", "        del res\n", "        if frame_idx % 200 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write counts file into the SAME local run folder as the video\n", "    txt_path_local = out_dir_local / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path_local, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "    print(\"  ✅ Wrote counts:\", txt_path_local)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "    # ---------- MOVE THIS VIDEO'S FOLDER TO DRIVE ----------\n", "    dest = DRIVE_PROJECT / out_dir_local.name  # keep the auto-numbered folder name\n", "    if dest.exists():\n", "        # extremely rare; if exists, add suffix\n", "        i = 2\n", "        while (DRIVE_PROJECT / f\"{out_dir_local.name}_{i}\").exists():\n", "            i += 1\n", "        dest = DRIVE_PROJECT / f\"{out_dir_local.name}_{i}\"\n", "\n", "    shutil.move(str(out_dir_local), str(dest))\n", "    print(\"📦 Moved results to Drive:\", dest)\n", "\n", "print(\"\\n✅ Done. All per-video folders (annotated video + *_counts.txt) are under:\", DRIVE_PROJECT)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 599}, "id": "IsIJkKFpmhBB", "outputId": "c4d07ed9-6ab4-4b57-f1cc-7269adadfd78"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === ONE CELL: per-video save (local, streamed) + unique-ID counts + move to Drive ===\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import shutil, math, torch, gc\n", "\n", "# ---------------- CONFIG ----------------\n", "MODEL = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "\n", "SRC_DIR = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "DRIVE_PROJECT = Path(\"/content/drive/MyDrive/yolo_runs\")\n", "RUN_NAME = \"video_preds_polygons\"      # YOLO will auto-number per video\n", "\n", "LOCAL_PROJECT = Path(\"/content/vid_tmp\")  # local temp output\n", "\n", "# Predict (video saving) settings\n", "IMGSZ_VID = 640          # use 640 if you have headroom\n", "VID_STRIDE_VID = 2\n", "CONF = 0.5\n", "USE_FP16 = True\n", "RETINA_MASKS = False\n", "PRINT_EVERY_VID = 100    # heartbeat during saving\n", "\n", "# Tracking (counting) settings\n", "IMGSZ_CNT = 640\n", "VID_STRIDE_CNT = 2\n", "TRACKER = \"bytetrack.yaml\"\n", "PRINT_EVERY_CNT = 100\n", "\n", "# -------------- PREP --------------\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "LOCAL_PROJECT.mkdir(parents=True, exist_ok=True)\n", "DRIVE_PROJECT.mkdir(parents=True, exist_ok=True)\n", "\n", "model = YOLO(MODEL)\n", "\n", "for vf in videos:\n", "    print(f\"\\n==================== {vf.name} ====================\")\n", "\n", "    # ---------- PASS A: SAVE ANNOTATED VIDEO LOCALLY (streamed, with progress) ----------\n", "    print(\"• Saving annotated video locally (streaming, no RAM buildup)...\")\n", "    out_dir_local = None\n", "    frame_idx = 0\n", "\n", "    for res in model.predict(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_VID,\n", "        conf=CONF,\n", "        save=True,\n", "        project=str(LOCAL_PROJECT),\n", "        name=RUN_NAME,           # auto-numbered folder will be created\n", "        vid_stride=VID_STRIDE_VID,\n", "        half=USE_FP16,\n", "        retina_masks=RETINA_MASKS,\n", "        verbose=False,\n", "        device=0,\n", "        stream=True,             # <<--- IMPORTANT: stream results, don't accumulate\n", "    ):\n", "        if out_dir_local is None:\n", "            out_dir_local = Path(res.save_dir)   # e.g., /content/vid_tmp/video_preds_polygons3\n", "            print(\"  Local run dir:\", out_dir_local)\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY_VID == 0:\n", "            print(f\"   saved frame {frame_idx}\")\n", "        # free per-frame object\n", "        del res\n", "        if frame_idx % 200 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    if out_dir_local is None:\n", "        print(\"  ⚠️ No frames saved; skipping counts and move.\")\n", "        continue\n", "\n", "    # ---------- PASS B: COUNT UNIQUE DEFECTS (NO VIDEO SAVED) ----------\n", "    print(\"• Counting unique defects with tracking (no saving, streaming)...\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,               # do NOT save frames here\n", "        stream=True,              # generator\n", "        stream_buffer=False,      # don't hold old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY_CNT == 0:\n", "            print(f\"   processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        del res\n", "        if frame_idx % 200 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write counts file into the SAME local run folder as the video\n", "    txt_path_local = out_dir_local / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path_local, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "    print(\"  ✅ Wrote counts:\", txt_path_local)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "    # ---------- MOVE THIS VIDEO'S FOLDER TO DRIVE ----------\n", "    dest = DRIVE_PROJECT / out_dir_local.name  # keep auto-numbered folder name\n", "    if dest.exists():\n", "        i = 2\n", "        while (DRIVE_PROJECT / f\"{out_dir_local.name}_{i}\").exists():\n", "            i += 1\n", "        dest = DRIVE_PROJECT / f\"{out_dir_local.name}_{i}\"\n", "    shutil.move(str(out_dir_local), str(dest))\n", "    print(\"📦 Moved results to Drive:\", dest)\n", "\n", "print(\"\\n✅ Done. All per-video folders (annotated video + *_counts.txt) are under:\", DRIVE_PROJECT)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Y8I5c5IEmvEV", "outputId": "5f70ddcd-f48f-41ec-dea5-2c3c4d3b48a5"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE CELL: save annotated videos AND write unique-ID counts, with auto-numbered run folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"    # parent folder for runs\n", "RUN_NAME    = \"video_preds_polygons\"                # base name (YOLO will append numbers automatically)\n", "CONF        = 0.5\n", "\n", "# Video saving pass (prettier output)\n", "IMGSZ_VID   = 640\n", "VID_STRIDE_VID = 1\n", "\n", "# Counting pass (RAM-safe + faster)\n", "IMGSZ_CNT   = 640\n", "VID_STRIDE_CNT = 2\n", "USE_FP16    = True\n", "TRACKER     = \"bytetrack.yaml\"\n", "PRINT_EVERY = 50\n", "VIDEO_EXTS  = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ================= CHECK SOURCE =================\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# ================= LOAD MODEL =================\n", "model = YOLO(MODEL)\n", "\n", "# ================= PASS 1: SAVE ANNOTATED VIDEOS =================\n", "print(\"Saving annotated videos (YOLO will auto-append run folder number if needed)...\")\n", "pred_results = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,     # <-- no exist_ok, so YOLO creates video_preds_polygons, ...2, ...3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "# Get the actual auto-numbered folder YOLO just created\n", "if not pred_results:\n", "    raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir)\n", "print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "# ================= PASS 2: COUNT UNIQUE DEFECTS PER VIDEO =================\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # DO NOT save frames in counting pass\n", "        stream=True,                # generator\n", "        stream_buffer=False,        # don't buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs present when tracking works\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write per-video counts file into the SAME run_dir as the videos\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "gIvKatQGnyI2", "outputId": "7b7964dd-b5b2-44bb-a692-f0db1036f50f"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "l2zKAEdtrcxt", "outputId": "a179fe66-507d-43ff-f393-dfa8d079045c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# --- ONE CELL: save annotated videos AND write unique-ID counts, with auto-numbered run folder ---\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "# ================= CONFIG =================\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"    # parent folder for runs\n", "RUN_NAME    = \"video_preds_polygons\"                # base name (YOLO will append numbers automatically)\n", "CONF        = 0.5\n", "\n", "# Video saving pass (prettier output)\n", "IMGSZ_VID   = 640\n", "VID_STRIDE_VID = 1\n", "\n", "# Counting pass (RAM-safe + faster)\n", "IMGSZ_CNT   = 640\n", "VID_STRIDE_CNT = 2\n", "USE_FP16    = True\n", "TRACKER     = \"bytetrack.yaml\"\n", "PRINT_EVERY = 50\n", "VIDEO_EXTS  = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "# ================= CHECK SOURCE =================\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "# ================= LOAD MODEL =================\n", "model = YOLO(MODEL)\n", "\n", "# ================= PASS 1: SAVE ANNOTATED VIDEOS =================\n", "print(\"Saving annotated videos (YOLO will auto-append run folder number if needed)...\")\n", "pred_results = model.predict(\n", "    source=str(SRC_DIR),\n", "    imgsz=IMGSZ_VID,\n", "    conf=CONF,\n", "    save=True,\n", "    project=PROJECT,\n", "    name=RUN_NAME,     # <-- no exist_ok, so YOLO creates video_preds_polygons, ...2, ...3, etc.\n", "    vid_stride=VID_STRIDE_VID,\n", "    verbose=True,\n", ")\n", "\n", "# Get the actual auto-numbered folder YOLO just created\n", "if not pred_results:\n", "    raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir)\n", "print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "# ================= PASS 2: COUNT UNIQUE DEFECTS PER VIDEO =================\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    # stream=True + save=False keeps RAM usage low\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,                 # DO NOT save frames in counting pass\n", "        stream=True,                # generator\n", "        stream_buffer=False,        # don't buffer old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0:\n", "            print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)  # tracker IDs present when tracking works\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        # keep memory tidy on long videos\n", "        del res\n", "        if frame_idx % 100 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write per-video counts file into the SAME run_dir as the videos\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "    print(\"  ✅ Wrote counts:\", txt_path)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "pQemOFuctqc6", "outputId": "41475a2a-95a1-41ae-f02c-b04cdce9c6de"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === ONE CELL: per-video save (local, streamed) + unique-ID counts + move to Drive ===\n", "\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import shutil, math, torch, gc\n", "\n", "# ---------------- CONFIG ----------------\n", "MODEL = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "\n", "SRC_DIR = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "DRIVE_PROJECT = Path(\"/content/drive/MyDrive/yolo_runs\")\n", "RUN_NAME = \"video_preds_polygons\"      # YOLO will auto-number per video\n", "\n", "LOCAL_PROJECT = Path(\"/content/vid_tmp\")  # local temp output\n", "\n", "# Predict (video saving) settings\n", "IMGSZ_VID = 640          # use 640 if you have headroom\n", "VID_STRIDE_VID = 2\n", "CONF = 0.5\n", "USE_FP16 = True\n", "RETINA_MASKS = False\n", "PRINT_EVERY_VID = 100    # heartbeat during saving\n", "\n", "# Tracking (counting) settings\n", "IMGSZ_CNT = 640\n", "VID_STRIDE_CNT = 2\n", "TRACKER = \"bytetrack.yaml\"\n", "PRINT_EVERY_CNT = 100\n", "\n", "# -------------- PREP --------------\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos:\n", "    raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "LOCAL_PROJECT.mkdir(parents=True, exist_ok=True)\n", "DRIVE_PROJECT.mkdir(parents=True, exist_ok=True)\n", "\n", "model = YOLO(MODEL)\n", "\n", "for vf in videos:\n", "    print(f\"\\n==================== {vf.name} ====================\")\n", "\n", "    # ---------- PASS A: SAVE ANNOTATED VIDEO LOCALLY (streamed, with progress) ----------\n", "    print(\"• Saving annotated video locally (streaming, no RAM buildup)...\")\n", "    out_dir_local = None\n", "    frame_idx = 0\n", "\n", "    for res in model.predict(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_VID,\n", "        conf=CONF,\n", "        save=True,\n", "        project=str(LOCAL_PROJECT),\n", "        name=RUN_NAME,           # auto-numbered folder will be created\n", "        vid_stride=VID_STRIDE_VID,\n", "        half=USE_FP16,\n", "        retina_masks=RETINA_MASKS,\n", "        verbose=False,\n", "        device=0,\n", "        stream=True,             # <<--- IMPORTANT: stream results, don't accumulate\n", "    ):\n", "        if out_dir_local is None:\n", "            out_dir_local = Path(res.save_dir)   # e.g., /content/vid_tmp/video_preds_polygons3\n", "            print(\"  Local run dir:\", out_dir_local)\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY_VID == 0:\n", "            print(f\"   saved frame {frame_idx}\")\n", "        # free per-frame object\n", "        del res\n", "        if frame_idx % 200 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    if out_dir_local is None:\n", "        print(\"  ⚠️ No frames saved; skipping counts and move.\")\n", "        continue\n", "\n", "    # ---------- PASS B: COUNT UNIQUE DEFECTS (NO VIDEO SAVED) ----------\n", "    print(\"• Counting unique defects with tracking (no saving, streaming)...\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None\n", "    had_ids = False\n", "    frame_idx = 0\n", "\n", "    for res in model.track(\n", "        source=str(vf),\n", "        imgsz=IMGSZ_CNT,\n", "        conf=CONF,\n", "        tracker=TRACKER,\n", "        device=0,\n", "        save=False,               # do NOT save frames here\n", "        stream=True,              # generator\n", "        stream_buffer=False,      # don't hold old frames\n", "        half=USE_FP16,\n", "        vid_stride=VID_STRIDE_CNT,\n", "        verbose=False,\n", "    ):\n", "        if names is None:\n", "            names = res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY_CNT == 0:\n", "            print(f\"   processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None:\n", "            continue\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)\n", "        if id_t is None or cls_t is None:\n", "            continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None:\n", "                continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0):\n", "                continue\n", "            if isinstance(tid, (int, float)) and tid < 0:\n", "                continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        del res\n", "        if frame_idx % 200 == 0:\n", "            torch.cuda.empty_cache(); gc.collect()\n", "\n", "    # Write counts file into the SAME local run folder as the video\n", "    txt_path_local = out_dir_local / f\"{vf.stem}_counts.txt\"\n", "    if had_ids and unique_ids_per_class:\n", "        lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s) > 0]\n", "    else:\n", "        lines = [\"No detections\"]\n", "    with open(txt_path_local, \"w\") as f:\n", "        f.write(\"\\n\".join(lines) + \"\\n\")\n", "    print(\"  ✅ Wrote counts:\", txt_path_local)\n", "    for L in lines:\n", "        print(\"   \", L)\n", "\n", "    # ---------- MOVE THIS VIDEO'S FOLDER TO DRIVE ----------\n", "    dest = DRIVE_PROJECT / out_dir_local.name  # keep auto-numbered folder name\n", "    if dest.exists():\n", "        i = 2\n", "        while (DRIVE_PROJECT / f\"{out_dir_local.name}_{i}\").exists():\n", "            i += 1\n", "        dest = DRIVE_PROJECT / f\"{out_dir_local.name}_{i}\"\n", "    shutil.move(str(out_dir_local), str(dest))\n", "    print(\"📦 Moved results to Drive:\", dest)\n", "\n", "print(\"\\n✅ Done. All per-video folders (annotated video + *_counts.txt) are under:\", DRIVE_PROJECT)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "yTZhV3-otzO6", "outputId": "c723db16-8b49-4511-af86-f762f9d5e900"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n"], "metadata": {"id": "_bxx1OSSwQXI", "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "b2870130-7ba5-413b-fd37-e8359f09523e"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install ultralytics --quiet\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "uch2NLH_SzO4", "outputId": "7ed8e1ca-2d0b-453b-adee-eb2ece913279"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Bkn2MumKTfIw", "outputId": "d74b1077-0a99-4ca2-9fb4-5ca7418f6fac"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n"], "metadata": {"id": "dGfe9feYTo0I"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# ====== PREDICT (keep as you have it above) ======\n", "# model = YOLO(MODEL)\n", "# results = model.predict(\n", "#     source=SOURCE, imgsz=IMGSZ, conf=CONF, save=True, max_det=300,\n", "#     project=PROJECT, name=RUN_NAME,\n", "# )\n", "\n", "# ====== JSON + CROPS + COUNTS + OVERLAY (REPLACE your old per-image loop with this) ======\n", "import os, json, math, numpy as np, cv2, torch\n", "from pathlib import Path\n", "from collections import Counter\n", "\n", "SAVE_JSON = True\n", "SAVE_CROPS = True          # set False if you don't want crops\n", "PAD_PX = 8                 # padding around crop\n", "BOX_ALPHA = 0.35           # counts box transparency\n", "\n", "def to_int_list(x): return [int(round(v)) for v in x]\n", "\n", "def poly_area_px2(points_xy):\n", "    if len(points_xy) < 3: return 0.0\n", "    pts = np.asarray(points_xy, dtype=np.float32)\n", "    return float(cv2.contourArea(pts))\n", "\n", "def clamp_bbox(x1, y1, x2, y2, w, h):\n", "    x1 = max(0, min(int(math.floor(x1)), w - 1))\n", "    y1 = max(0, min(int(math.floor(y1)), h - 1))\n", "    x2 = max(0, min(int(math.ceil(x2)),  w - 1))\n", "    y2 = max(0, min(int(math.ceil(y2)),  h - 1))\n", "    if x2 <= x1: x2 = min(x1 + 1, w - 1)\n", "    if y2 <= y1: y2 = min(y1 + 1, h - 1)\n", "    return x1, y1, x2, y2\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "    return cv2.imwrite(str(img_path), img)\n", "\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    direct = save_dir / src_path.name\n", "    if direct.exists(): return direct\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # e.g., .../trial_preds_polygons5/\n", "    json_dir  = final_dir / \"json\"\n", "    crops_dir = final_dir / \"crops\"\n", "    if SAVE_JSON:  json_dir.mkdir(parents=True, exist_ok=True)\n", "    if SAVE_CROPS: crops_dir.mkdir(parents=True, exist_ok=True)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)\n", "        src_path = Path(res.path)\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        names = res.names\n", "        dets, cls_idxs, confs, bboxes = [], [], [], []\n", "\n", "        if getattr(res, \"boxes\", None) is not None:\n", "            if getattr(res.boxes, \"cls\", None) is not None:\n", "                cls_raw = res.boxes.cls\n", "                cls_idxs = (cls_raw.detach().cpu().tolist()\n", "                            if isinstance(cls_raw, torch.Tensor) else list(cls_raw))\n", "                cls_idxs = [int(x) for x in cls_idxs]\n", "            if getattr(res.boxes, \"conf\", None) is not None:\n", "                conf_raw = res.boxes.conf\n", "                confs = (conf_raw.detach().cpu().tolist()\n", "                         if isinstance(conf_raw, torch.Tensor) else list(conf_raw))\n", "            if getattr(res.boxes, \"xyxy\", None) is not None:\n", "                xyxy = res.boxes.xyxy\n", "                if isinstance(xyxy, torch.Tensor):\n", "                    xyxy = xyxy.detach().cpu().numpy()\n", "                bboxes = xyxy.tolist()\n", "\n", "        polys_xy = None\n", "        if getattr(res, \"masks\", None) is not None and getattr(res.masks, \"xy\", None) is not None:\n", "            polys_xy = res.masks.xy  # list of (Kx2) arrays in image coords\n", "\n", "        N = len(polys_xy) if polys_xy is not None else len(bboxes)\n", "        img_bgr = cv2.imread(str(src_path))\n", "        ih, iw = (img_bgr.shape[0], img_bgr.shape[1]) if img_bgr is not None else (None, None)\n", "\n", "        for i in range(N):\n", "            cls_name = names[cls_idxs[i]] if i < len(cls_idxs) else names[0]\n", "            conf     = float(confs[i]) if i < len(confs) else None\n", "\n", "            if i < len(bboxes):\n", "                x1, y1, x2, y2 = bboxes[i]\n", "            else:\n", "                if polys_xy is not None and i < len(polys_xy) and len(polys_xy[i]) >= 3:\n", "                    px, py = polys_xy[i][:,0], polys_xy[i][:,1]\n", "                    x1, y1, x2, y2 = float(px.min()), float(py.min()), float(px.max()), float(py.max())\n", "                else:\n", "                    x1 = y1 = 0.0\n", "                    x2 = float(iw - 1) if iw else 1.0\n", "                    y2 = float(ih - 1) if ih else 1.0\n", "            bbox = [int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))]\n", "\n", "            poly_flat, area_px2 = [], None\n", "            if polys_xy is not None and i < len(polys_xy) and len(polys_xy[i]) >= 3:\n", "                pts = polys_xy[i]\n", "                area_px2 = poly_area_px2(pts)\n", "                poly_flat = to_int_list(pts.reshape(-1).tolist())\n", "            else:\n", "                if iw is not None and ih is not None:\n", "                    area_px2 = max(1, (bbox[2]-bbox[0])*(bbox[3]-bbox[1]))\n", "\n", "            crop_rel_path = None\n", "            if SAVE_CROPS and img_bgr is not None:\n", "                x1p, y1p, x2p, y2p = clamp_bbox(bbox[0]-PAD_PX, bbox[1]-PAD_PX, bbox[2]+PAD_PX, bbox[3]+PAD_PX, iw, ih)\n", "                crop = img_bgr[y1p:y2p, x1p:x2p]\n", "                if crop.size > 0:\n", "                    cls_dir = crops_dir / cls_name\n", "                    cls_dir.mkdir(parents=True, exist_ok=True)\n", "                    crop_name = f\"{src_path.stem}_{cls_name}_{i:02d}.jpg\"\n", "                    cv2.imwrite(str(cls_dir / crop_name), crop)\n", "                    crop_rel_path = str(Path(\"crops\") / cls_name / crop_name)\n", "\n", "            dets.append({\n", "                \"class\": cls_name,\n", "                \"bbox_xyxy\": bbox,\n", "                \"poly_xy_flat\": poly_flat,\n", "                \"area_px2\": area_px2,\n", "                \"conf\": conf,\n", "                \"crop_relpath\": crop_rel_path\n", "            })\n", "\n", "        if SAVE_JSON:\n", "            rec = {\"image_path\": str(src_path), \"save_path\": str(out_img) if out_img else None, \"detections\": dets}\n", "            (final_dir / \"json\").mkdir(exist_ok=True)\n", "            with open(final_dir / \"json\" / f\"{src_path.stem}.json\", \"w\") as f:\n", "                json.dump(rec, f, indent=2)\n", "\n", "        counts = Counter([d[\"class\"] for d in dets]) if dets else {}\n", "        lines = [f\"{k}: {counts[k]}\" for k in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        if out_img is not None:\n", "            if overlay_counts_on_image(out_img, lines):\n", "                print(f\"✅ JSON/Crops/Counts written for {out_img.name}\")\n", "            else:\n", "                print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done: JSON at\", final_dir / \"json\", \"| Crops at\", final_dir / \"crops\" if SAVE_CROPS else \"(skipped)\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 211}, "id": "yN5KCcH5Tvzv", "outputId": "e998b539-8ee1-4e5e-c59c-04eb5f886c52"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# =========================\n", "# YOLOv11 IMAGE PRED + JSON/CROPS EXPORT (Colab-ready)\n", "# =========================\n", "\n", "# --- Install (if needed) ---\n", "# !pip install ultralytics opencv-python-headless==4.10.0.84\n", "\n", "import os, json, math, glob\n", "from pathlib import Path\n", "from collections import Counter\n", "\n", "import cv2\n", "import numpy as np\n", "import torch\n", "import torch.nn.functional as F\n", "\n", "from ultralytics import YOLO\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# =========================\n", "# CONFIG: EDIT THESE\n", "# =========================\n", "MODEL    = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE   = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT  = \"/content/drive/MyDrive/yolo_runs\"  # where YOLO saves runs\n", "RUN_NAME = \"trial_preds_polygons\"              # run folder name (YOLO may append a suffix)\n", "IMGSZ    = 640\n", "CONF     = 0.5\n", "MAX_DET  = 300\n", "\n", "# Exports\n", "SAVE_JSON   = True\n", "SAVE_CROPS  = True\n", "PAD_PX      = 8        # bbox padding for crops\n", "BOX_ALPHA   = 0.35     # overlay transparency for the counts box\n", "\n", "# =========================\n", "# PATCH: Polygon-only overlays (no boxes, no shaded masks, no confidences)\n", "# =========================\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)  # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "\n", "__orig_plot = Results.plot\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled.\")\n", "\n", "# =========================\n", "# HELPERS\n", "# =========================\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "def to_int_list(x):\n", "    return [int(round(v)) for v in x]\n", "\n", "def poly_area_px2(points_xy):\n", "    if len(points_xy) < 3:\n", "        return 0.0\n", "    pts = np.asarray(points_xy, dtype=np.float32)\n", "    return float(cv2.contourArea(pts))\n", "\n", "def clamp_bbox(x1, y1, x2, y2, w, h):\n", "    x1 = max(0, min(int(math.floor(x1)), w - 1))\n", "    y1 = max(0, min(int(math.floor(y1)), h - 1))\n", "    x2 = max(0, min(int(math.ceil(x2)),  w - 1))\n", "    y2 = max(0, min(int(math.ceil(y2)),  h - 1))\n", "    if x2 <= x1: x2 = min(x1 + 1, w - 1)\n", "    if y2 <= y1: y2 = min(y1 + 1, h - 1)\n", "    return x1, y1, x2, y2\n", "\n", "# =========================\n", "# PREDICT\n", "# =========================\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=MAX_DET,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# =========================\n", "# POSTPROCESS: JSON + CROPS + COUNTS OVERLAY\n", "# =========================\n", "import math  # used in clamp_bbox\n", "\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)   # e.g., .../trial_preds_polygons5/\n", "    json_dir  = final_dir / \"json\"\n", "    crops_dir = final_dir / \"crops\"\n", "\n", "    if SAVE_JSON:\n", "        json_dir.mkdir(parents=True, exist_ok=True)\n", "    if SAVE_CROPS:\n", "        crops_dir.mkdir(parents=True, exist_ok=True)\n", "\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    total_images = 0\n", "    total_dets = 0\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)\n", "        src_path = Path(res.path)\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        names = res.names\n", "        dets, cls_idxs, confs, bboxes = [], [], [], []\n", "\n", "        # boxes\n", "        if getattr(res, \"boxes\", None) is not None:\n", "            if getattr(res.boxes, \"cls\", None) is not None:\n", "                cls_raw = res.boxes.cls\n", "                cls_idxs = (cls_raw.detach().cpu().tolist()\n", "                            if isinstance(cls_raw, torch.Tensor) else list(cls_raw))\n", "                cls_idxs = [int(x) for x in cls_idxs]\n", "            if getattr(res.boxes, \"conf\", None) is not None:\n", "                conf_raw = res.boxes.conf\n", "                confs = (conf_raw.detach().cpu().tolist()\n", "                         if isinstance(conf_raw, torch.Tensor) else list(conf_raw))\n", "            if getattr(res.boxes, \"xyxy\", None) is not None:\n", "                xyxy = res.boxes.xyxy\n", "                if isinstance(xyxy, torch.Tensor):\n", "                    xyxy = xyxy.detach().cpu().numpy()\n", "                bboxes = xyxy.tolist()\n", "\n", "        # polygons (image coords)\n", "        polys_xy = None\n", "        if getattr(res, \"masks\", None) is not None and getattr(res.masks, \"xy\", None) is not None:\n", "            polys_xy = res.masks.xy  # list of (Kx2) arrays\n", "\n", "        N = len(polys_xy) if polys_xy is not None else len(bboxes)\n", "\n", "        img_bgr = cv2.imread(str(src_path))\n", "        ih, iw = (img_bgr.shape[0], img_bgr.shape[1]) if img_bgr is not None else (None, None)\n", "\n", "        for i in range(N):\n", "            cls_name = names[cls_idxs[i]] if i < len(cls_idxs) else names[0]\n", "            conf     = float(confs[i]) if i < len(confs) else None\n", "\n", "            if i < len(bboxes):\n", "                x1, y1, x2, y2 = bboxes[i]\n", "            else:\n", "                if polys_xy is not None and i < len(polys_xy) and len(polys_xy[i]) >= 3:\n", "                    px, py = polys_xy[i][:, 0], polys_xy[i][:, 1]\n", "                    x1, y1, x2, y2 = float(px.min()), float(py.min()), float(px.max()), float(py.max())\n", "                else:\n", "                    x1 = y1 = 0.0\n", "                    x2 = float(iw - 1) if iw else 1.0\n", "                    y2 = float(ih - 1) if ih else 1.0\n", "\n", "            bbox = [int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))]\n", "\n", "            # polygon + area\n", "            poly_flat, area_px2 = [], None\n", "            if polys_xy is not None and i < len(polys_xy) and len(polys_xy[i]) >= 3:\n", "                pts = polys_xy[i]\n", "                area_px2 = poly_area_px2(pts)\n", "                poly_flat = to_int_list(pts.reshape(-1).tolist())\n", "            else:\n", "                if iw is not None and ih is not None:\n", "                    area_px2 = max(1, (bbox[2]-bbox[0])*(bbox[3]-bbox[1]))\n", "\n", "            # crop (optional)\n", "            crop_rel_path = None\n", "            if SAVE_CROPS and img_bgr is not None:\n", "                x1p, y1p, x2p, y2p = clamp_bbox(bbox[0]-PAD_PX, bbox[1]-PAD_PX, bbox[2]+PAD_PX, bbox[3]+PAD_PX, iw, ih)\n", "                crop = img_bgr[y1p:y2p, x1p:x2p]\n", "                if crop.size > 0:\n", "                    cls_dir = crops_dir / cls_name\n", "                    cls_dir.mkdir(parents=True, exist_ok=True)\n", "                    crop_name = f\"{src_path.stem}_{cls_name}_{i:02d}.jpg\"\n", "                    cv2.imwrite(str(cls_dir / crop_name), crop)\n", "                    crop_rel_path = str(Path(\"crops\") / cls_name / crop_name)\n", "\n", "            dets.append({\n", "                \"class\": cls_name,\n", "                \"bbox_xyxy\": bbox,\n", "                \"poly_xy_flat\": poly_flat,\n", "                \"area_px2\": area_px2,\n", "                \"conf\": conf,\n", "                \"crop_relpath\": crop_rel_path\n", "            })\n", "\n", "        # JSON\n", "        if SAVE_JSON:\n", "            rec = {\"image_path\": str(src_path), \"save_path\": str(out_img) if out_img else None, \"detections\": dets}\n", "            with open(json_dir / f\"{src_path.stem}.json\", \"w\") as f:\n", "                json.dump(rec, f, indent=2)\n", "\n", "        # counts + overlay\n", "        counts = Counter([d[\"class\"] for d in dets]) if dets else {}\n", "        lines = [f\"{k}: {counts[k]}\" for k in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        if out_img is not None:\n", "            overlay_counts_on_image(out_img, lines)\n", "\n", "        total_images += 1\n", "        total_dets   += len(dets)\n", "\n", "        print(f\"✅ {src_path.name}: {len(dets)} detections | counts ->\", \", \".join(lines))\n", "\n", "    print(\"\\n🎉 Done\")\n", "    if SAVE_JSON:  print(\"   JSON dir :\", json_dir)\n", "    if SAVE_CROPS: print(\"   Crops dir:\", crops_dir)\n", "    print(f\"   Images processed: {total_images} | Total detections: {total_dets}\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "JizPEyM6V2SQ", "outputId": "68128d14-7b10-499f-ba60-821c87008b58"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "jEsRbcs7WtN8", "outputId": "3c7a9804-3bbb-4b2a-bd1b-84c84d06474e"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# =========================\n", "# KEEP PREDICT EXACTLY AS YOU WROTE IT\n", "# =========================\n", "from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "import os, json, math, numpy as np  # extra imports for the new block\n", "\n", "# ====== CONFIG (exactly yours) ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test 2\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # results root\n", "RUN_NAME = \"trial_preds_polygons\"              # YOLO may append a number\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background (used below)\n", "\n", "# ====== PREDICT (unchanged) ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# =========================\n", "# NEW: JSON + CROPS + COUNTS + OVERLAY  (replaces your old per-image loop)\n", "# =========================\n", "\n", "# toggles\n", "SAVE_JSON  = True\n", "SAVE_CROPS = True\n", "PAD_PX     = 8   # small padding around bbox for crops\n", "\n", "def to_int_list(x):\n", "    return [int(round(v)) for v in x]\n", "\n", "def poly_area_px2(points_xy):\n", "    \"\"\"Compute polygon area in px^2 from Nx2 image-coord points.\"\"\"\n", "    if points_xy is None or len(points_xy) < 3:\n", "        return 0.0\n", "    pts = np.asarray(points_xy, dtype=np.float32)\n", "    return float(cv2.contourArea(pts))\n", "\n", "def clamp_bbox(x1, y1, x2, y2, w, h):\n", "    x1 = max(0, min(int(math.floor(x1)), w - 1))\n", "    y1 = max(0, min(int(math.floor(y1)), h - 1))\n", "    x2 = max(0, min(int(math.ceil(x2)),  w - 1))\n", "    y2 = max(0, min(int(math.ceil(y2)),  h - 1))\n", "    if x2 <= x1: x2 = min(x1 + 1, w - 1)\n", "    if y2 <= y1: y2 = min(y1 + 1, h - 1)\n", "    return x1, y1, x2, y2\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # e.g., .../trial_preds_polygons5/\n", "    json_dir  = final_dir / \"json\"\n", "    crops_dir = final_dir / \"crops\"\n", "    if SAVE_JSON:\n", "        json_dir.mkdir(parents=True, exist_ok=True)\n", "    if SAVE_CROPS:\n", "        crops_dir.mkdir(parents=True, exist_ok=True)\n", "\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    total_images = 0\n", "    total_dets = 0\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) saved visualization produced by your polygon-only patch\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        names = res.names\n", "        dets, cls_idxs, confs, bboxes = [], [], [], []\n", "\n", "        # 2) boxes, classes, confidences\n", "        if getattr(res, \"boxes\", None) is not None:\n", "            if getattr(res.boxes, \"cls\", None) is not None:\n", "                cls_raw = res.boxes.cls\n", "                cls_idxs = (cls_raw.detach().cpu().tolist()\n", "                            if isinstance(cls_raw, torch.Tensor) else list(cls_raw))\n", "                cls_idxs = [int(x) for x in cls_idxs]\n", "            if getattr(res.boxes, \"conf\", None) is not None:\n", "                conf_raw = res.boxes.conf\n", "                confs = (conf_raw.detach().cpu().tolist()\n", "                         if isinstance(conf_raw, torch.Tensor) else list(conf_raw))\n", "            if getattr(res.boxes, \"xyxy\", None) is not None:\n", "                xyxy = res.boxes.xyxy\n", "                if isinstance(xyxy, torch.Tensor):\n", "                    xyxy = xyxy.detach().cpu().numpy()\n", "                bboxes = xyxy.tolist()\n", "\n", "        # 3) polygons in image coords (preferred for area)\n", "        polys_xy = None\n", "        if getattr(res, \"masks\", None) is not None and getattr(res.masks, \"xy\", None) is not None:\n", "            polys_xy = res.masks.xy  # list of (Kx2) arrays\n", "\n", "        # 4) iterate detections\n", "        N = len(polys_xy) if polys_xy is not None else len(bboxes)\n", "\n", "        img_bgr = cv2.imread(str(src_path))\n", "        ih, iw = (img_bgr.shape[0], img_bgr.shape[1]) if img_bgr is not None else (None, None)\n", "\n", "        for i in range(N):\n", "            cls_name = names[cls_idxs[i]] if i < len(cls_idxs) else names[0]\n", "            conf     = float(confs[i]) if i < len(confs) else None\n", "\n", "            # bbox from boxes or from polygon bounds\n", "            if i < len(bboxes):\n", "                x1, y1, x2, y2 = bboxes[i]\n", "            else:\n", "                if polys_xy is not None and i < len(polys_xy) and len(polys_xy[i]) >= 3:\n", "                    px, py = polys_xy[i][:, 0], polys_xy[i][:, 1]\n", "                    x1, y1, x2, y2 = float(px.min()), float(py.min()), float(px.max()), float(py.max())\n", "                else:\n", "                    x1 = y1 = 0.0\n", "                    x2 = float(iw - 1) if iw else 1.0\n", "                    y2 = float(ih - 1) if ih else 1.0\n", "            bbox = [int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))]\n", "\n", "            # polygon + area\n", "            poly_flat, area_px2 = [], None\n", "            if polys_xy is not None and i < len(polys_xy) and len(polys_xy[i]) >= 3:\n", "                pts = polys_xy[i]\n", "                area_px2 = poly_area_px2(pts)\n", "                poly_flat = to_int_list(pts.reshape(-1).tolist())\n", "            else:\n", "                if iw is not None and ih is not None:\n", "                    area_px2 = max(1, (bbox[2]-bbox[0])*(bbox[3]-bbox[1]))\n", "\n", "            # optional crop\n", "            crop_rel_path = None\n", "            if SAVE_CROPS and img_bgr is not None:\n", "                x1p, y1p, x2p, y2p = clamp_bbox(bbox[0]-PAD_PX, bbox[1]-PAD_PX, bbox[2]+PAD_PX, bbox[3]+PAD_PX, iw, ih)\n", "                crop = img_bgr[y1p:y2p, x1p:x2p]\n", "                if crop.size > 0:\n", "                    cls_dir = crops_dir / cls_name\n", "                    cls_dir.mkdir(parents=True, exist_ok=True)\n", "                    crop_name = f\"{src_path.stem}_{cls_name}_{i:02d}.jpg\"\n", "                    cv2.imwrite(str(cls_dir / crop_name), crop)\n", "                    crop_rel_path = str(Path(\"crops\") / cls_name / crop_name)\n", "\n", "            dets.append({\n", "                \"class\": cls_name,\n", "                \"bbox_xyxy\": bbox,\n", "                \"poly_xy_flat\": poly_flat,   # [] if no mask\n", "                \"area_px2\": area_px2,\n", "                \"conf\": conf,\n", "                \"crop_relpath\": crop_rel_path\n", "            })\n", "\n", "        # 5) JSON per image\n", "        if SAVE_JSON:\n", "            rec = {\n", "                \"image_path\": str(src_path),\n", "                \"save_path\": str(out_img) if out_img else None,\n", "                \"detections\": dets\n", "            }\n", "            with open(json_dir / f\"{src_path.stem}.json\", \"w\") as f:\n", "                json.dump(rec, f, indent=2)\n", "\n", "        # 6) counts + overlay\n", "        counts = Counter([d[\"class\"] for d in dets]) if dets else {}\n", "        lines = [f\"{k}: {counts[k]}\" for k in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        if out_img is not None:\n", "            overlay_counts_on_image(out_img, lines)\n", "\n", "        total_images += 1\n", "        total_dets   += len(dets)\n", "        print(f\"✅ {src_path.name}: {len(dets)} detections | counts ->\", \", \".join(lines))\n", "\n", "    print(\"\\n🎉 Done\")\n", "    if SAVE_JSON:  print(\"   JSON dir :\", json_dir)\n", "    if SAVE_CROPS: print(\"   Crops dir:\", crops_dir)\n", "    print(f\"   Images processed: {total_images} | Total detections: {total_dets}\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "67WbRt6sbOrV", "outputId": "4948ad8f-6c87-4305-d224-ab3cf51c3122"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n"], "metadata": {"id": "dXuaLEuDbcNY", "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "a312e7da-239c-47e6-bb89-a75aa1a9b7cf"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install ultralytics --quiet"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "uxEpTdc_p-2f", "outputId": "0c0c7403-6f19-43c6-d08e-86d921ec3fc6"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "qqxcbmmGqJsj", "outputId": "c5b27545-5a91-49c4-ba51-4ff595e23410"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n"], "metadata": {"id": "TQsTHgxcqcuT"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "6ocI1anDqkx8", "outputId": "583abe59-23c2-4045-a434-413ce5a3aa94"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "pU2bcYeArcO5", "outputId": "e8c3119e-5fe4-42f5-9591-7c118380d4e1"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/images cowley county\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 373}, "id": "Vz8Vg2b_tEtA", "outputId": "19b8fcc6-4c26-4b7d-8056-17e57c62abb8"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "oPBAOFdttkJM", "outputId": "2eab4d40-d31a-4c39-c39c-2646e90d0cd3"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install ultralytics --quiet"], "metadata": {"id": "IhpI4Hc6u2qP"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "HAQMwwVau6AJ", "outputId": "1545fd18-d11c-44db-bd40-6ddf6c446df9"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n"], "metadata": {"id": "YUK7JOoBvBta"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/images cowley county\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "k0a7F1XkvG35", "outputId": "03bafcae-2c4b-4f94-8f6e-257f4a45566b"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "uMpf6J_yvmox", "outputId": "d19a2192-3db3-4d63-d44d-95c2e27a9daa"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install ultralytics --quiet"], "metadata": {"id": "9sWCSOpZzOuN"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "UsQRMzMazSA6", "outputId": "11926bff-1945-485f-d33c-5c2c2a894712"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n"], "metadata": {"id": "ySqvjevuzdR-"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/images saline county\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "N8i8rBapzhVl", "outputId": "80c75b42-ba59-4760-e8aa-1d66ec1fc7db"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/images sedgwick county\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "QH0Nk3K_0NSE", "outputId": "aba5cfa9-f799-454c-a4cc-79297a813993"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n"], "metadata": {"id": "XTz0BNZC1fT-", "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "4a955acd-2419-42e4-977b-92712699744b"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%pip install ultralytics --quiet"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "y-bzaeM-WWk1", "outputId": "2c5e4f82-49d4-4b5d-dfff-98497a8734bf"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === Polygon-only overlays for Ultralytics YOLO (no boxes, no shaded masks, no confidences) ===\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "# 1) Disable box labels (kills rectangles + conf text)\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n", "    return\n", "\n", "# 2) Disable shaded masks\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False):\n", "    return\n", "\n", "# 3) Add polygon contour drawer with label (unshaded)\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    \"\"\"\n", "    Draw polygon contours from a mask (tensor or uint8 array), no fill, with class label.\n", "    \"\"\"\n", "    # Upsample + threshold if tensor\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)                       # [1,1,H,W]\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]),\n", "                          mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "\n", "    # Extract full-resolution contours\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3:\n", "            continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10),\n", "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "# Apply patches to the Annotator\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "# 4) Patch Results.plot to call our polygon drawer instead of shaded masks/boxes\n", "__orig_plot = Results.plot\n", "\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    \"\"\"\n", "    Replacement for Results.plot:\n", "    - no rectangles, no conf text, no filled masks\n", "    - draws only polygon contours + class label\n", "    \"\"\"\n", "    # Build fresh annotator image\n", "    im = (self.orig_img.copy()\n", "          if hasattr(self, \"orig_img\") and self.orig_img is not None\n", "          else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "\n", "    if pred_masks is not None and hasattr(pred_masks, \"data\") and pred_masks.data is not None:\n", "        # Use class indices from boxes (if present), else default class 0\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled (no boxes, no shaded masks, no confidences).\")\n", "print(\"   Restart runtime to undo the patch.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "O7zq4zZlWnrt", "outputId": "4080b213-0b2f-4495-c986-af98114ac73e"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "model = YOLO(\"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\")\n"], "metadata": {"id": "hoDWzyhQWuIT"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "\n", "# ====== CONFIG ======\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test\"  # folder of test IMAGES\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"   # this is the folder where the results are saved\n", "RUN_NAME = \"trial_preds_polygons\"   # and this is the name that will be given for each new folder where the predict will be stored YOLO may append a number if it already exists\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35  # transparency for the counts box background\n", "\n", "# ====== PREDICT ======\n", "model = YOLO(MODEL)\n", "results = model.predict(\n", "    source=SOURCE,\n", "    imgsz=IMGSZ,\n", "    conf=CONF,\n", "    save=True,\n", "    max_det=300,\n", "    project=PROJECT,\n", "    name=RUN_NAME,\n", ")\n", "\n", "# ====== HELPERS ======\n", "def find_saved_image(save_dir: Path, src_path: Path) -> Path | None:\n", "    \"\"\"\n", "    Find the actual visualization file YOLO wrote for a given source image.\n", "    We try the straightforward path, then fall back to matching by stem.\n", "    \"\"\"\n", "    direct = save_dir / src_path.name\n", "    if direct.exists():\n", "        return direct\n", "    # fallback: same stem, any extension (handles JPG/PNG case, name tweaks)\n", "    matches = list(save_dir.glob(src_path.stem + \".*\"))\n", "    return matches[0] if matches else None\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img = cv2.imread(str(img_path))\n", "    if img is None:\n", "        print(f\"⚠️ Could not read image for overlay: {img_path}\")\n", "        return False\n", "    # background box size\n", "    sizes = [cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w = max(sizes) + 20\n", "    line_h = 28\n", "    box_h = line_h * max(1, len(lines)) + 20\n", "    x0, y0 = 5, 5\n", "\n", "    overlay = img.copy()\n", "    cv2.rectangle(overlay, (x0, y0), (x0 + box_w, y0 + box_h), (0, 0, 0), -1)\n", "    img = cv2.addWeighted(overlay, box_alpha, img, 1 - box_alpha, 0)\n", "\n", "    y = y0 + 20\n", "    for t in lines:\n", "        cv2.putText(img, t, (x0 + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n", "                    (255, 255, 255), 2, cv2.LINE_AA)\n", "        y += line_h\n", "\n", "    ok = cv2.imwrite(str(img_path), img)\n", "    if not ok:\n", "        print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "# ====== PER-IMAGE COUNTS + SAVE TXT + OVERLAY ======\n", "if not results:\n", "    print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir)  # actual run folder (e.g., .../trial_preds_polygons5/)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    for res in results:\n", "        save_dir = Path(res.save_dir)  # per-result (same as final_dir)\n", "        src_path = Path(res.path)\n", "\n", "        # 1) find the actual saved visualization for this source image\n", "        out_img = find_saved_image(save_dir, src_path)\n", "        if out_img is None:\n", "            print(f\"⚠️ Could not locate saved image for {src_path.name} in {save_dir}\")\n", "            continue\n", "\n", "        # 2) collect predicted classes from boxes\n", "        cls_idxs = []\n", "        if getattr(res, \"boxes\", None) is not None and getattr(res.boxes, \"cls\", None) is not None:\n", "            cls_tensor = res.boxes.cls\n", "            cls_idxs = [int(x) for x in (cls_tensor.detach().cpu().tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor)]\n", "\n", "        counts = Counter(cls_idxs)\n", "        lines = [f\"{res.names[i]}: {counts[i]}\" for i in sorted(counts.keys())] if counts else [\"No detections\"]\n", "\n", "        # 3) write per-image counts text file\n", "        txt_path = save_dir / f\"{src_path.stem}_counts.txt\"\n", "        with open(txt_path, \"w\") as f:\n", "            f.write(\"\\n\".join(lines) + \"\\n\")\n", "\n", "        # 4) overlay counts box on the saved visualization\n", "        if overlay_counts_on_image(out_img, lines):\n", "            print(f\"✅ Overlay + counts written for {out_img.name}\")\n", "        else:\n", "            print(f\"⚠️ Skipped overlay for {out_img.name}\")\n", "\n", "    print(\"✅ Done.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "gIpbm3m-Wx_N", "outputId": "0e9d7f5a-1b64-402a-ea41-f80399a68721"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === EDIT ONLY THIS: put your existing repo name (the one that already has the VM code) ===\n", "REPO_NAME   = \"concrete-defect-yolov11\"   # e.g., \"yolo11-concrete-defects\"\n", "# ==========================================================================================\n", "\n", "GITHUB_USER = \"natnaeltaye\"\n", "BRANCH_NAME = \"add-colab-workflow\"  # feature branch we will PR into main\n", "\n", "# Git identity\n", "!git config --global user.name \"natnaeltaye\"\n", "!git config --global user.email \"myprecioushs@gmail.com\"\n", "\n", "print(\"Configured git:\", !git config user.name, \"/\", !git config user.email)\n", "print(f\"Target repo: https://github.com/{GITHUB_USER}/{REPO_NAME}\")\n", "print(f\"Branch to create: {BRANCH_NAME}\")\n"], "metadata": {"id": "jmCjt-l2XCWS", "colab": {"base_uri": "https://localhost:8080/", "height": 106}, "outputId": "8a19f7eb-b573-4560-cf55-2e6d9805e1c9"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# === EDIT ONLY THIS: put your existing repo name (the one that already has the VM code) ===\n", "REPO_NAME   = \"concrete-defect-yolov11\"\n", "# ==========================================================================================\n", "\n", "GITHUB_USER = \"natnaeltaye\"\n", "BRANCH_NAME = \"add-colab-workflow\"  # feature branch we will PR into main\n", "\n", "# Git identity\n", "!git config --global user.name \"natnaeltaye\"\n", "!git config --global user.email \"myprecioushs@gmail.com\"\n", "\n", "# Show configured identity (run as separate shell commands)\n", "print(\"Configured git:\")\n", "!git config user.name\n", "!git config user.email\n", "\n", "# These are normal Python prints – no shell \"!\" here\n", "print(f\"Target repo: https://github.com/{GITHUB_USER}/{REPO_NAME}\")\n", "print(f\"Branch to create: {BRANCH_NAME}\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "KVfuijOyASjG", "outputId": "c1ae5904-844e-4fb0-99e1-aac76c35152d"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Create a classic GitHub PAT with 'repo' scope, then paste it below (input is hidden)\n", "GITHUB_PAT = input(\"Paste your GitHub PAT (hidden): \").strip()\n", "assert len(GITHUB_PAT) > 20, \"Token looks too short. Generate a classic PAT with 'repo' scope.\"\n", "print(\"✅ Token captured in memory.\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "e60AezunAuuf", "outputId": "58189eac-c217-4b0d-de78-aab5868726a0"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import os, shutil, pathlib\n", "\n", "REPO_NAME = \"concrete-defect-yolov11\"   # (already set before)\n", "GITHUB_USER = \"natnaeltaye\"\n", "BRANCH_NAME = \"add-colab-workflow\"\n", "\n", "workdir = f\"/content/{REPO_NAME}\"\n", "if pathlib.Path(workdir).exists():\n", "    shutil.rmtree(workdir)\n", "\n", "clone_url = f\"https://github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n", "!git clone \"$clone_url\" \"$workdir\"\n", "%cd \"$workdir\"\n", "\n", "# Create feature branch\n", "!git checkout -b \"{BRANCH_NAME}\"\n", "\n", "# Prepare folder structure\n", "!mkdir -p colab/scripts\n", "print(\"✅ Cloned repo and created branch:\", BRANCH_NAME)\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "TWZiU5C3A-xY", "outputId": "a2264ca5-06f6-408b-af20-1ee8e5385a49"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from pathlib import Path\n", "\n", "content = r'''import os, shutil, random, math\n", "from pathlib import Path\n", "\n", "# ==== CONFIG ====\n", "BASE = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025\")\n", "DATASET = BASE / \"dataset\"\n", "TRAIN   = BASE / \"train\"\n", "VAL     = BASE / \"val\"\n", "VAL_RATIO = 0.17\n", "RANDOM_SEED = 42\n", "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n", "OVERWRITE = True\n", "\n", "# ==== PREP ====\n", "if not DATASET.exists():\n", "    raise FileNotFoundError(f\"Dataset folder not found: {DATASET}\")\n", "\n", "def clean_dir(d: Path):\n", "    if d.exists():\n", "        if OVERWRITE: shutil.rmtree(d)\n", "        else: raise RuntimeError(f\"{d} exists. Set OVERWRITE=True or rename it first.\")\n", "    d.mkdir(parents=True, exist_ok=True)\n", "\n", "clean_dir(TRAIN); clean_dir(VAL)\n", "\n", "# ==== COLLECT ELIGIBLE SAMPLES (image + matching .txt) ====\n", "samples = []\n", "for p in DATASET.rglob(\"*\"):\n", "    if p.is_file() and p.suffix.lower() in IMG_EXTS:\n", "        txt = p.with_suffix(\".txt\")\n", "        if txt.exists():\n", "            samples.append((p, txt))\n", "\n", "if not samples:\n", "    raise RuntimeError(f\"No (image, txt) pairs found under {DATASET}\")\n", "\n", "# ==== SHUFFLE & SPLIT ====\n", "random.seed(RANDOM_SEED)\n", "random.shuffle(samples)\n", "n_total = len(samples)\n", "n_val = math.floor(n_total * VAL_RATIO)\n", "val_samples = samples[:n_val]\n", "train_samples = samples[n_val:]\n", "\n", "# ==== COPY ====\n", "def copy_pair(img: Path, txt: Path, dst_dir: Path):\n", "    dst_dir.mkdir(parents=True, exist_ok=True)\n", "    import shutil as _sh\n", "    _sh.copy2(img, dst_dir / img.name)\n", "    _sh.copy2(txt, dst_dir / txt.name)\n", "\n", "for img, txt in val_samples: copy_pair(img, txt, VAL)\n", "for img, txt in train_samples: copy_pair(img, txt, TRAIN)\n", "\n", "# ==== REPORT ====\n", "def count_images(d: Path): return sum(1 for f in d.glob(\"*\") if f.suffix.lower() in IMG_EXTS)\n", "def count_txts(d: Path):    return sum(1 for f in d.glob(\"*.txt\"))\n", "\n", "print(f\"Total pairs found: {n_total}\")\n", "print(f\"Train pairs: {len(train_samples)} | images={count_images(TRAIN)} | labels={count_txts(TRAIN)}\")\n", "print(f\"Val   pairs: {len(val_samples)}   | images={count_images(VAL)}   | labels={count_txts(VAL)}\")\n", "\n", "# ==== WRITE A YOLO DATA YAML ====\n", "yaml_text = f\"\"\"# Auto-generated for Colab\n", "path: {BASE}\n", "train: {TRAIN}\n", "val: {VAL}\n", "\n", "names:\n", "  0: Crack\n", "  1: ACrack\n", "  2: Efflorescence\n", "  3: WConccor\n", "  4: Spalling\n", "  5: Wetspot\n", "  6: Rust\n", "  7: ExposedRebars\n", "\"\"\"\n", "yaml_path = BASE / \"data_colab.yaml\"\n", "yaml_path.write_text(yaml_text)\n", "print(f\"Wrote {yaml_path}\")\n", "'''\n", "Path(\"colab/scripts\").mkdir(parents=True, exist_ok=True)\n", "Path(\"colab/scripts/step5_split_and_yaml.py\").write_text(content)\n", "print(\"✅ Wrote colab/scripts/step5_split_and_yaml.py\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "62bSkOiuEx__", "outputId": "b98f3b93-190a-456c-c697-39d5f669eb48"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from pathlib import Path\n", "content = r'''# Polygon-only overlays (no boxes, no shaded masks, no confidences)\n", "import cv2, numpy as np, torch\n", "import torch.nn.functional as F\n", "from ultralytics.utils.plotting import Annotator, colors\n", "from ultralytics.engine.results import Results\n", "\n", "def _box_label_noop(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)): return\n", "def _masks_noop(self, masks, colors, im_gpu, alpha: float = 0.5, retina_masks: bool = False): return\n", "\n", "def _segmentation(self, mask, label='', color=(0, 255, 0), thresh: float = 0.30):\n", "    if isinstance(mask, torch.Tensor):\n", "        m = mask.unsqueeze(0).unsqueeze(0)\n", "        m = F.interpolate(m, size=(self.im.shape[0], self.im.shape[1]), mode='bilinear', align_corners=False)\n", "        m = (m.squeeze().detach().cpu().numpy() > thresh).astype(np.uint8)\n", "    else:\n", "        m = mask\n", "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n", "    for cnt in contours:\n", "        if len(cnt) < 3: continue\n", "        cv2.polylines(self.im, [cnt], isClosed=True, color=color, thickness=self.lw)\n", "        if label:\n", "            x, y = cnt[0][0]\n", "            cv2.putText(self.im, label, (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n", "\n", "Annotator.box_label = _box_label_noop\n", "Annotator.masks = _masks_noop\n", "Annotator.segmentation = _segmentation\n", "\n", "__orig_plot = Results.plot\n", "def _plot_polygons_only(self, conf=True, boxes=True, masks=True, probs=False, labels=True, *args, **kwargs):\n", "    im = (self.orig_img.copy() if getattr(self, \"orig_img\", None) is not None else self.plot_img.copy())\n", "    annotator = Annotator(im, example=str(self.names))\n", "    pred_masks = getattr(self, \"masks\", None)\n", "    pred_boxes = getattr(self, \"boxes\", None)\n", "    if getattr(pred_masks, \"data\", None) is not None:\n", "        classes = (pred_boxes.cls.tolist() if (pred_boxes is not None and hasattr(pred_boxes, \"cls\"))\n", "                   else [0] * len(pred_masks.data))\n", "        for m, cls_idx in zip(pred_masks.data, classes):\n", "            cls_idx = int(cls_idx)\n", "            annotator.segmentation(m, label=self.names[cls_idx], color=colors(cls_idx, bgr=True))\n", "    return annotator.result()\n", "\n", "Results.plot = _plot_polygons_only\n", "print(\"✅ Ultralytics patched: polygon-only overlays enabled.\")\n", "print(\"   Restart runtime to undo the patch.\")\n", "'''\n", "Path(\"colab/scripts\").mkdir(parents=True, exist_ok=True)\n", "Path(\"colab/scripts/step8_patch_ultralytics_polygons.py\").write_text(content)\n", "print(\"✅ Wrote colab/scripts/step8_patch_ultralytics_polygons.py\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "sOz7NvJrGgzH", "outputId": "75cd447a-b7cc-4353-f637-c86e655b8f68"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from pathlib import Path\n", "content = r'''from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import Counter\n", "import cv2, torch\n", "import os, json, math, numpy as np\n", "\n", "MODEL   = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SOURCE  = \"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test 2\"\n", "PROJECT = \"/content/drive/MyDrive/yolo_runs\"\n", "RUN_NAME = \"trial_preds_polygons\"\n", "IMGSZ   = 640\n", "CONF    = 0.5\n", "BOX_ALPHA = 0.35\n", "\n", "model = YOLO(MODEL)\n", "results = model.predict(source=SOURCE, imgsz=IMGSZ, conf=CONF, save=True, max_det=300, project=PROJECT, name=RUN_NAME)\n", "\n", "SAVE_JSON, SAVE_CROPS, PAD_PX = True, True, 8\n", "\n", "def to_int_list(x): return [int(round(v)) for v in x]\n", "def poly_area_px2(points_xy):\n", "    if points_xy is None or len(points_xy) < 3: return 0.0\n", "    return float(cv2.contourArea(np.asarray(points_xy, dtype=np.float32)))\n", "def clamp_bbox(x1,y1,x2,y2,w,h):\n", "    x1=max(0,min(int(math.floor(x1)),w-1)); y1=max(0,min(int(math.floor(y1)),h-1))\n", "    x2=max(0,min(int(math.ceil(x2)), w-1)); y2=max(0,min(int(math.ceil(y2)), h-1))\n", "    if x2<=x1:x2=min(x1+1,w-1)\n", "    if y2<=y1:y2=min(y1+1,h-1)\n", "    return x1,y1,x2,y2\n", "\n", "def overlay_counts_on_image(img_path: Path, lines, box_alpha=BOX_ALPHA):\n", "    img=cv2.imread(str(img_path))\n", "    if img is None: print(f\"⚠️ Could not read image for overlay: {img_path}\"); return False\n", "    sizes=[cv2.getTextSize(t, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0][0] for t in lines] or [1]\n", "    box_w=max(sizes)+20; line_h=28; box_h=line_h*max(1,len(lines))+20; x0,y0=5,5\n", "    ov=img.copy(); cv2.rectangle(ov,(x0,y0),(x0+box_w,y0+box_h),(0,0,0),-1)\n", "    img=cv2.addWeighted(ov, box_alpha, img, 1-box_alpha, 0)\n", "    y=y0+20\n", "    for t in lines:\n", "        cv2.putText(img,t,(x0+10,y),cv2.FONT_HERSHEY_SIMPLEX,0.9,(255,255,255),2,cv2.LINE_AA); y+=line_h\n", "    ok=cv2.imwrite(str(img_path),img)\n", "    if not ok: print(f\"⚠️ Failed to write overlay to: {img_path}\")\n", "    return ok\n", "\n", "def find_saved_image(save_dir: Path, src_path: Path):\n", "    direct=save_dir/src_path.name\n", "    if direct.exists(): return direct\n", "    m=list(save_dir.glob(src_path.stem+\".*\"))\n", "    return m[0] if m else None\n", "\n", "if not results: print(\"No results returned.\")\n", "else:\n", "    final_dir = Path(results[0].save_dir); json_dir=final_dir/\"json\"; crops_dir=final_dir/\"crops\"\n", "    if SAVE_JSON: json_dir.mkdir(parents=True, exist_ok=True)\n", "    if SAVE_CROPS: crops_dir.mkdir(parents=True, exist_ok=True)\n", "    print(\"Writing outputs in:\", final_dir)\n", "\n", "    total_images=0; total_dets=0\n", "    for res in results:\n", "        save_dir=Path(res.save_dir); src_path=Path(res.path)\n", "        out_img=find_saved_image(save_dir, src_path)\n", "        if out_img is None: print(f\"⚠️ No saved image for {src_path.name} in {save_dir}\"); continue\n", "\n", "        names=res.names; dets=[]; cls_idxs=[]; confs=[]; bboxes=[]\n", "        if getattr(res,\"boxes\",None) is not None:\n", "            if getattr(res.boxes,\"cls\",None) is not None:\n", "                cls_raw=res.boxes.cls; cls_idxs=(cls_raw.detach().cpu().tolist() if isinstance(cls_raw,torch.Tensor) else list(cls_raw)); cls_idxs=[int(x) for x in cls_idxs]\n", "            if getattr(res.boxes,\"conf\",None) is not None:\n", "                conf_raw=res.boxes.conf; confs=(conf_raw.detach().cpu().tolist() if isinstance(conf_raw,torch.Tensor) else list(conf_raw))\n", "            if getattr(res.boxes,\"xyxy\",None) is not None:\n", "                xyxy=res.boxes.xyxy;\n", "                if isinstance(xyxy,torch.Tensor): xyxy=xyxy.detach().cpu().numpy()\n", "                bboxes=xyxy.tolist()\n", "\n", "        polys_xy=None\n", "        if getattr(res,\"masks\",None) is not None and getattr(res.masks,\"xy\",None) is not None:\n", "            polys_xy=res.masks.xy\n", "\n", "        N=len(polys_xy) if polys_xy is not None else len(bboxes)\n", "        img_bgr=cv2.imread(str(src_path)); ih,iw=(img_bgr.shape[0],img_bgr.shape[1]) if img_bgr is not None else (None,None)\n", "\n", "        for i in range(N):\n", "            cls_name=names[cls_idxs[i]] if i<len(cls_idxs) else names[0]\n", "            conf=float(confs[i]) if i<len(confs) else None\n", "            if i<len(bboxes):\n", "                x1,y1,x2,y2=bboxes[i]\n", "            else:\n", "                if polys_xy is not None and i<len(polys_xy) and len(polys_xy[i])>=3:\n", "                    px,py=polys_xy[i][:,0],polys_xy[i][:,1]; x1,y1,x2,y2=float(px.min()),float(py.min()),float(px.max()),float(py.max())\n", "                else:\n", "                    x1=y1=0.0; x2=float(iw-1) if iw else 1.0; y2=float(ih-1) if ih else 1.0\n", "            bbox=[int(round(x1)),int(round(y1)),int(round(x2)),int(round(y2))]\n", "\n", "            poly_flat=[]; area_px2=None\n", "            if polys_xy is not None and i<len(polys_xy) and len(polys_xy[i])>=3:\n", "                pts=polys_xy[i]; area_px2=poly_area_px2(pts); poly_flat=to_int_list(pts.reshape(-1).tolist())\n", "            else:\n", "                if iw is not None and ih is not None: area_px2=max(1,(bbox[2]-bbox[0])*(bbox[3]-bbox[1]))\n", "\n", "            # crops\n", "            crop_rel_path=None\n", "            if SAVE_CROPS and img_bgr is not None:\n", "                x1p,y1p,x2p,y2p=clamp_bbox(bbox[0]-PAD_PX,bbox[1]-PAD_PX,bbox[2]+PAD_PX,bbox[3]+PAD_PX,iw,ih)\n", "                crop=img_bgr[y1p:y2p, x1p:x2p]\n", "                if crop.size>0:\n", "                    cls_dir=crops_dir/cls_name; cls_dir.mkdir(parents=True, exist_ok=True)\n", "                    crop_name=f\"{src_path.stem}_{cls_name}_{i:02d}.jpg\"\n", "                    cv2.imwrite(str(cls_dir/crop_name), crop)\n", "                    crop_rel_path=str(Path(\"crops\")/cls_name/crop_name)\n", "\n", "            dets.append({\"class\":cls_name,\"bbox_xyxy\":bbox,\"poly_xy_flat\":poly_flat,\"area_px2\":area_px2,\"conf\":conf,\"crop_relpath\":crop_rel_path})\n", "\n", "        if SAVE_JSON:\n", "            rec={\"image_path\":str(src_path),\"save_path\":str(out_img) if out_img else None,\"detections\":dets}\n", "            (json_dir/f\"{src_path.stem}.json\").write_text(json.dumps(rec, indent=2))\n", "\n", "        counts=Counter([d[\"class\"] for d in dets]) if dets else {}\n", "        lines=[f\"{k}: {counts[k]}\" for k in sorted(counts.keys())] if counts else [\"No detections\"]\n", "        (save_dir/f\"{src_path.stem}_counts.txt\").write_text(\"\\n\".join(lines)+\"\\n\")\n", "        if out_img is not None: overlay_counts_on_image(out_img, lines)\n", "\n", "        total_images=total_images+1 if 'total_images' in globals() else 1\n", "        total_dets=total_dets+len(dets) if 'total_dets' in globals() else len(dets)\n", "        print(f\"✅ {src_path.name}: {len(dets)} detections | counts ->\", \", \".join(lines))\n", "\n", "    print(\"\\n🎉 Done\")\n", "    if SAVE_JSON:  print(\"   JSON dir :\", json_dir)\n", "    if SAVE_CROPS: print(\"   Crops dir:\", crops_dir)\n", "    print(f\"   Images processed: {total_images} | Total detections: {total_dets}\")\n", "'''\n", "Path(\"colab/scripts\").mkdir(parents=True, exist_ok=True)\n", "Path(\"colab/scripts/step9_predict_images.py\").write_text(content)\n", "print(\"✅ Wrote colab/scripts/step9_predict_images.py\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "115-mEUuGlAE", "outputId": "c69b5301-c032-424c-a828-c46ebd5b9907"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from pathlib import Path\n", "content = r'''from ultralytics import YOLO\n", "from pathlib import Path\n", "from collections import defaultdict\n", "import math, torch, gc\n", "\n", "MODEL       = \"/content/drive/MyDrive/yolo_runs/train_colab_m640/weights/best.pt\"\n", "SRC_DIR     = Path(\"/content/drive/MyDrive/YOLOv11_Concrete-defect-dataset-08202025/trial test videos 2\")\n", "PROJECT     = \"/content/drive/MyDrive/yolo_runs\"\n", "RUN_NAME    = \"video_preds_polygons\"\n", "CONF        = 0.5\n", "\n", "IMGSZ_VID      = 640\n", "VID_STRIDE_VID = 1\n", "IMGSZ_CNT      = 640\n", "VID_STRIDE_CNT = 2\n", "USE_FP16       = True\n", "TRACKER        = \"bytetrack.yaml\"\n", "PRINT_EVERY    = 50\n", "VIDEO_EXTS     = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".m4v\"}\n", "\n", "videos = [p for p in SRC_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS]\n", "if not videos: raise SystemExit(f\"No videos found in {SRC_DIR}\")\n", "\n", "model = YOLO(MODEL)\n", "\n", "print(\"Saving annotated videos...\")\n", "pred_results = model.predict(source=str(SRC_DIR), imgsz=IMGSZ_VID, conf=CONF, save=True, project=PROJECT, name=RUN_NAME, vid_stride=VID_STRIDE_VID, verbose=True)\n", "if not pred_results: raise SystemExit(\"No prediction results returned.\")\n", "run_dir = Path(pred_results[0].save_dir); print(f\"\\n✅ Videos saved to: {run_dir}\")\n", "\n", "print(\"\\nCounting unique defects (no video saving)...\")\n", "for vf in videos:\n", "    print(f\"\\n▶ {vf.name}\")\n", "    unique_ids_per_class = defaultdict(set)\n", "    names = None; had_ids=False; frame_idx=0\n", "\n", "    for res in model.track(source=str(vf), imgsz=IMGSZ_CNT, conf=CONF, tracker=TRACKER, device=0, save=False, stream=True, stream_buffer=False, half=USE_FP16, vid_stride=VID_STRIDE_CNT, verbose=False):\n", "        if names is None: names=res.names\n", "        frame_idx += 1\n", "        if frame_idx % PRINT_EVERY == 0: print(f\"  processed frame {frame_idx}\")\n", "\n", "        boxes = getattr(res, \"boxes\", None)\n", "        if boxes is None: continue\n", "\n", "        cls_t = getattr(boxes, \"cls\", None)\n", "        id_t  = getattr(boxes, \"id\",  None)\n", "        if id_t is None or cls_t is None: continue\n", "\n", "        had_ids = True\n", "        clses = cls_t.detach().cpu().tolist() if isinstance(cls_t, torch.Tensor) else list(cls_t or [])\n", "        ids   = id_t.detach().cpu().tolist()  if isinstance(id_t,  torch.Tensor) else list(id_t  or [])\n", "\n", "        for c, tid in zip(clses, ids):\n", "            if tid is None: continue\n", "            if isinstance(tid, float) and (math.isnan(tid) or tid < 0): continue\n", "            if isinstance(tid, (int, float)) and tid < 0: continue\n", "            unique_ids_per_class[int(c)].add(int(tid))\n", "\n", "        del res\n", "        if frame_idx % 100 == 0: torch.cuda.empty_cache(); gc.collect()\n", "\n", "    txt_path = run_dir / f\"{vf.stem}_counts.txt\"\n", "    lines = [f\"{names[c]}: {len(s)}\" for c, s in sorted(unique_ids_per_class.items()) if len(s)>0] if (had_ids and unique_ids_per_class) else [\"No detections\"]\n", "    with open(txt_path, \"w\") as f: f.write(\"\\n\".join(lines) + \"\\n\")\n", "    print(\"  ✅ Wrote counts:\", txt_path); [print(\"   \", L) for L in lines]\n", "\n", "print(\"\\n🎬 Done. Videos and *_counts.txt are in:\", run_dir)\n", "'''\n", "Path(\"colab/scripts\").mkdir(parents=True, exist_ok=True)\n", "Path(\"colab/scripts/step10_predict_videos_bytetrack.py\").write_text(content)\n", "print(\"✅ Wrote colab/scripts/step10_predict_videos_bytetrack.py\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "qZkEjG2mGn5_", "outputId": "330dd020-4036-4eed-ce62-dcd642a1629c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from pathlib import Path\n", "\n", "GITHUB_USER = \"natnaeltaye\"\n", "REPO_NAME = \"concrete-defect-yolov11\"\n", "BRANCH_NAME = \"add-colab-workflow\"\n", "\n", "colab_md = f\"\"\"# Google Colab Workflow\n", "\n", "This folder contains a Colab notebook and helper scripts to reproduce training and inference without a VM.\n", "\n", "## Open in Colab\n", "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n", "https://colab.research.google.com/github/{GITHUB_USER}/{REPO_NAME}/blob/{BRANCH_NAME}/colab/YOLOv11-Concrete-defects-training-08202025.ipynb)\n", "\n", "## Contents\n", "- `YOLOv11-Concrete-defects-training-08202025.ipynb` – end-to-end steps (1–10).\n", "- `scripts/`:\n", "  - `step5_split_and_yaml.py`\n", "  - `step8_patch_ultralytics_polygons.py`\n", "  - `step9_predict_images.py`\n", "  - `step10_predict_videos_bytetrack.py`\n", "\n", "## Notes\n", "- Results save to Drive under `/content/drive/MyDrive/yolo_runs`.\n", "- Do not commit large outputs or model weights (`*.pt`, `*.onnx`). Use Zenodo or GitHub Releases and link them.\n", "- Hyperparameters and data YAML are defined in the notebook and scripts for reproducibility.\n", "\"\"\"\n", "Path(\"colab/README.md\").write_text(colab_md)\n", "\n", "top_add = \"\"\"\n", "## Reproduction Paths\n", "\n", "- **VM workflow**: see `vm/` for training on a virtual machine.\n", "- **Google Colab workflow**: see `colab/` for the end-to-end Colab notebook and helper scripts.\n", "  - One-click: use the Colab badge inside `colab/README.md`.\n", "\"\"\"\n", "if Path(\"README.md\").exists():\n", "    with open(\"README.md\",\"a\",encoding=\"utf-8\") as f: f.write(top_add)\n", "else:\n", "    Path(\"README.md\").write_text(\"# Project\\n\"+top_add)\n", "\n", "gitignore = \"\"\"\n", "# Large/ephemeral artifacts\n", "*.pt\n", "*.onnx\n", "*.mp4\n", "*.avi\n", "*.mov\n", "*.mkv\n", "*.m4v\n", "*.zip\n", "*.tar\n", "*.tar.gz\n", "*.7z\n", ".DS_Store\n", "\n", "# YOLO & Colab outputs\n", "yolo_runs/\n", "runs/\n", "outputs/\n", "*.json\n", "*.csv\n", "*.xlsx\n", "\"\"\"\n", "if Path(\".gitignore\").exists():\n", "    with open(\".gitignore\",\"a\",encoding=\"utf-8\") as f: f.write(\"\\n\"+gitignore.strip()+\"\\n\")\n", "else:\n", "    Path(\".gitignore\").write_text(gitignore.strip()+\"\\n\")\n", "\n", "print(\"✅ Wrote colab/README.md, updated README.md, and .gitignore\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "XBoH3MTVGq80", "outputId": "68b2fda1-73ff-481a-a59f-134bb30ef524"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["!git status\n", "!git add colab/ README.md .gitignore\n", "!git commit -m \"Add Colab workflow: separate scripts (Step5, Step8, Step9, Step10) + README + gitignore\"\n", "!git push --set-upstream origin add-colab-workflow\n", "print(\"✅ Branch pushed: add-colab-workflow\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "keN-w7dyGyS-", "outputId": "296a7780-aa53-4aa2-f310-76a0c18d8d00"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Upload your saved notebook file from your computer\n", "import os, shutil\n", "from google.colab import files\n", "\n", "print(\"👉 Choose: YOLOv11-Concrete-defects-training-08202025.ipynb\")\n", "uploaded = files.upload()\n", "nb_name = list(uploaded.keys())[0]\n", "os.makedirs(\"colab\", exist_ok=True)\n", "target = \"colab/YOLOv11-Concrete-defects-training-08202025.ipynb\"\n", "shutil.move(nb_name, target)\n", "print(f\"✅ Notebook placed at {target}\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 56}, "id": "QGRCP_cDG1aW", "outputId": "53b4b9a2-dbc5-41da-cb9c-b4261986297f"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["!git add colab/YOLOv11-Concrete-defects-training-08202025.ipynb\n", "!git commit -m \"Add Colab notebook (Steps 1–10)\"\n", "!git push\n"], "metadata": {"id": "nrbQMdK-HK9o"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": [], "metadata": {"id": "g0hiSmziHlnP"}, "execution_count": null, "outputs": []}]}